---
apiVersion: trainer.kubeflow.org/v1alpha1
kind: TrainingRuntime
metadata:
  name: pytorch-distributed
  namespace: mlteam
spec:
  mlPolicy:
    numNodes: 2
    torch:
      numProcPerNode: auto
  template:
    spec:
      replicatedJobs:
        - name: trainer
          replicas: 1
          template:
            spec:
              parallelism: 2
              completions: 2
              template:
                spec:
                  schedulerName: kai-scheduler
                  containers:
                    - name: trainer
                      image: nvcr.io/nvidia/pytorch:25.01-py3
                      command:
                        - bash
                        - -c
                        - |
                          echo "=== Environment ==="
                          echo "PET_NNODES=$PET_NNODES"
                          echo "PET_NPROC_PER_NODE=$PET_NPROC_PER_NODE"
                          echo "PET_MASTER_ADDR=$PET_MASTER_ADDR"
                          echo "PET_MASTER_PORT=$PET_MASTER_PORT"
                          echo "PET_NODE_RANK=$PET_NODE_RANK"
                          echo ""

                          torchrun \
                            --nnodes=${PET_NNODES:-2} \
                            --nproc_per_node=${PET_NPROC_PER_NODE:-1} \
                            --node_rank=${PET_NODE_RANK:-0} \
                            --master_addr=${PET_MASTER_ADDR} \
                            --master_port=${PET_MASTER_PORT:-29500} \
                            /workspace/train.py
                      env:
                        - name: NCCL_DEBUG
                          value: "INFO"
                        - name: NCCL_IB_DISABLE
                          value: "1"
                      resources:
                        requests:
                          cpu: "4"
                          memory: "16Gi"
                          nvidia.com/gpu: "1"
                        limits:
                          cpu: "8"
                          memory: "32Gi"
                          nvidia.com/gpu: "1"
                      volumeMounts:
                        - name: shm
                          mountPath: /dev/shm
                        - name: training-scripts
                          mountPath: /workspace
                  volumes:
                    - name: shm
                      emptyDir:
                        medium: Memory
                        sizeLimit: 8Gi
                    - name: training-scripts
                      configMap:
                        name: pytorch-train-script
                  restartPolicy: OnFailure


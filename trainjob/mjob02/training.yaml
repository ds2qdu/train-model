---
apiVersion: trainer.kubeflow.org/v1alpha1
kind: TrainJob
metadata:
  name: pytorch-distributed-sample
  namespace: mlteam
  annotations:
    kai.scheduler/queue: "mlteam-queue"
spec:
  runtimeRef:
    name: pytorch-distributed
    kind: TrainingRuntime
    apiGroup: trainer.kubeflow.org 
  trainer:
    image: nvcr.io/nvidia/pytorch:25.01-py3
    command:
      - bash
      - -c
      - |
        echo "=== Environment ==="
        echo "PET_NNODES=$PET_NNODES"
        echo "PET_NPROC_PER_NODE=$PET_NPROC_PER_NODE"
        echo "PET_MASTER_ADDR=$PET_MASTER_ADDR"
        echo "PET_MASTER_PORT=$PET_MASTER_PORT"
        echo "PET_NODE_RANK=$PET_NODE_RANK"

        torchrun \
          --nnodes=${PET_NNODES:-2} \
          --nproc_per_node=${PET_NPROC_PER_NODE:-1} \
          --node_rank=${PET_NODE_RANK:-0} \
          --master_addr=${PET_MASTER_ADDR} \
          --master_port=${PET_MASTER_PORT:-29500} \
          /workspace/train.py
    numNodes: 2
    numProcPerNode: 1
    resourcesPerNode:
      requests:
        cpu: "4"
        memory: "16Gi"
        nvidia.com/gpu: "1"
      limits:
        cpu: "8"
        memory: "32Gi"
        nvidia.com/gpu: "1"
    env:
      - name: NCCL_DEBUG
        value: "INFO"
      - name: NCCL_IB_DISABLE
        value: "1"
  podTemplateOverrides:
    - targetJobs:
        - name: trainer
      spec:
        tolerations:
          - key: "nvidia.com/gpu"
            operator: "Equal"
            value: "true"
            effect: "NoSchedule"


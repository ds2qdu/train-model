---
apiVersion: trainer.kubeflow.org/v1alpha1
kind: TrainingRuntime
metadata:
  name: mnist-runtime
  namespace: mlteam
spec:
  mlPolicy:
    numNodes: 2
    torch:
      numProcPerNode: auto
  template:
    spec:
      replicatedJobs:
        - name: trainer
          replicas: 1
          template:
            spec:
              parallelism: 2
              completions: 2
              template:
                spec:
                  schedulerName: kai-scheduler
                  containers:
                    - name: trainer
                      image: nvcr.io/nvidia/pytorch:25.12-py3
                      command:
                        - bash
                        - -c
                        - |
                          # 환경변수 수동 설정
                          export WORLD_SIZE=2
                          export RANK=${JOB_COMPLETION_INDEX:-0}
                          export MASTER_PORT=29500
                          export LOCAL_RANK=0

                          # MASTER_ADDR: Rank 0은 자신의 IP, Worker는 Rank 0의 IP
                          MY_IP=$(hostname -i | awk '{print $1}')

                          if [ "$RANK" == "0" ]; then
                              export MASTER_ADDR=$MY_IP
                          else
                              # Headless Service를 통해 다른 Pod IP 조회 (자신 제외)
                              echo "Waiting for master pod..."
                              echo "My IP: $MY_IP"
                              for i in $(seq 1 60); do
                                  # Service의 모든 IP 중 자신이 아닌 것 선택
                                  MASTER_ADDR=$(getent ahostsv4 mnist-training.mlteam.svc.cluster.local 2>/dev/null | awk '{print $1}' | grep -v "^${MY_IP}$" | head -1)
                                  if [ -n "$MASTER_ADDR" ]; then
                                      echo "Found master: $MASTER_ADDR"
                                      break
                                  fi
                                  echo "Waiting... ($i/60)"
                                  sleep 1
                              done
                              export MASTER_ADDR
                          fi

                          echo "=== Environment ==="
                          echo "WORLD_SIZE=$WORLD_SIZE"
                          echo "RANK=$RANK"
                          echo "MASTER_ADDR=$MASTER_ADDR"
                          echo "MASTER_PORT=$MASTER_PORT"
                          echo "MY_IP=$MY_IP"
                          echo ""

                          # Worker는 Master가 준비될 때까지 대기
                          if [ "$RANK" != "0" ]; then
                              echo "Waiting for master port..."
                              for i in $(seq 1 120); do
                                  if timeout 1 bash -c "</dev/tcp/$MASTER_ADDR/$MASTER_PORT" 2>/dev/null; then
                                      echo "Master is ready!"
                                      break
                                  fi
                                  sleep 1
                              done
                          fi

                          torchrun \
                            --nnodes=$WORLD_SIZE \
                            --nproc_per_node=1 \
                            --node_rank=$RANK \
                            --master_addr=$MASTER_ADDR \
                            --master_port=$MASTER_PORT \
                            /workspace/train.py
                      env:
                        - name: NCCL_DEBUG
                          value: "INFO"
                        - name: NCCL_IB_DISABLE
                          value: "1"
                        - name: NCCL_SOCKET_IFNAME
                          value: "eth0"
                        - name: NCCL_NET
                          value: "Socket"
                      resources:
                        requests:
                          cpu: "4"
                          memory: "16Gi"
                          nvidia.com/gpu: "1"
                        limits:
                          cpu: "8"
                          memory: "32Gi"
                          nvidia.com/gpu: "1"
                      volumeMounts:
                        - name: shm
                          mountPath: /dev/shm
                        - name: scripts
                          mountPath: /workspace
                        - name: storage
                          mountPath: /mnt/storage
                  volumes:
                    - name: shm
                      emptyDir:
                        medium: Memory
                        sizeLimit: 8Gi
                    - name: scripts
                      configMap:
                        name: mnist-train-script
                    - name: storage
                      persistentVolumeClaim:
                        claimName: mnist-pipeline-storage
                  restartPolicy: OnFailure
---
apiVersion: trainer.kubeflow.org/v1alpha1
kind: TrainJob
metadata:
  name: mnist-training
  namespace: mlteam
  annotations:
    kai.scheduler/queue: "mlteam-queue"
spec:
  runtimeRef:
    name: mnist-runtime
    kind: TrainingRuntime
    apiGroup: trainer.kubeflow.org 
  trainer:
    image: nvcr.io/nvidia/pytorch:25.12-py3
    command:
      - torchrun
    args:
      - --nnodes=2
      - --nproc_per_node=1
      - --master_addr=$(MASTER_ADDR)
      - --master_port=$(MASTER_PORT)
      - /workspace/train.py
      - --epochs=10
      - --batch-size=128
      - --lr=0.001
      - --checkpoint-dir=/mnt/storage/checkpoints
      - --export-dir=/mnt/storage/models
    numNodes: 2
    numProcPerNode: 1
    resourcesPerNode:
      requests:
        cpu: "4"
        memory: "16Gi"
        nvidia.com/gpu: "1"
      limits:
        cpu: "8"
        memory: "32Gi"
        nvidia.com/gpu: "1"
    env:
      - name: NCCL_DEBUG
        value: "INFO"
      - name: NCCL_IB_DISABLE
        value: "1"
      - name: NCCL_SOCKET_IFNAME
        value: "eth0"
  podTemplateOverrides:
    - targetJobs:
        - name: trainer
      spec:
        tolerations:
          - key: "nvidia.com/gpu"
            operator: "Equal"
            value: "true"
            effect: "NoSchedule"


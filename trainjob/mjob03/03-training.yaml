---
apiVersion: trainer.kubeflow.org/v1alpha1
kind: TrainingRuntime
metadata:
  name: mnist-runtime
  namespace: mlteam
spec:
  mlPolicy:
    numNodes: 2
    torch:
      numProcPerNode: "1"
  template:
    spec:
      replicatedJobs:
        - name: trainer
          replicas: 1
          template:
            spec:
              parallelism: 2
              completions: 2
              template:
                spec:
                  schedulerName: kai-scheduler
                  containers:
                    - name: trainer
                      image: nvcr.io/nvidia/pytorch:25.01-py3
                      env:
                        - name: NCCL_DEBUG
                          value: "INFO"
                        - name: NCCL_IB_DISABLE
                          value: "1"
                        - name: NCCL_SOCKET_IFNAME
                          value: "eth0"
                      resources:
                        requests:
                          cpu: "4"
                          memory: "16Gi"
                          nvidia.com/gpu: "1"
                        limits:
                          cpu: "8"
                          memory: "32Gi"
                          nvidia.com/gpu: "1"
                      volumeMounts:
                        - name: shm
                          mountPath: /dev/shm
                        - name: scripts
                          mountPath: /workspace
                        - name: storage
                          mountPath: /mnt/storage
                  volumes:
                    - name: shm
                      emptyDir:
                        medium: Memory
                        sizeLimit: 8Gi
                    - name: scripts
                      configMap:
                        name: mnist-train-script
                    - name: storage
                      persistentVolumeClaim:
                        claimName: mnist-pipeline-storage
                  restartPolicy: OnFailure
---
apiVersion: trainer.kubeflow.org/v1alpha1
kind: TrainJob
metadata:
  name: mnist-training
  namespace: mlteama
  annotations:
    kai.scheduler/queue: "mlteam-queue"
spec:
  runtimeRef:
    name: mnist-runtime
    kind: TrainingRuntime
  trainer:
    image: nvcr.io/nvidia/pytorch:25.01-py3
    command:
      - torchrun
    args:
      - --nnodes=2
      - --nproc_per_node=1
      - --master_addr=$(MASTER_ADDR)
      - --master_port=$(MASTER_PORT)
      - /workspace/train.py
      - --epochs=10
      - --batch-size=128
      - --lr=0.001
      - --checkpoint-dir=/mnt/storage/checkpoints
      - --export-dir=/mnt/storage/models
    numNodes: 2
    numProcPerNode: "1"
    resourcesPerNode:
      requests:
        cpu: "4"
        memory: "16Gi"
        nvidia.com/gpu: "1"
      limits:
        cpu: "8"
        memory: "32Gi"
        nvidia.com/gpu: "1"
    env:
      - name: NCCL_DEBUG
        value: "INFO"
      - name: NCCL_IB_DISABLE
        value: "1"
      - name: NCCL_SOCKET_IFNAME
        value: "eth0"

# 03-training.yaml
---
apiVersion: trainer.kubeflow.org/v1alpha1
kind: TrainingRuntime
metadata:
  name: mnist-runtime
  namespace: mlteam
spec:
  mlPolicy:
    numNodes: 2
    torch:
      numProcPerNode: "1"
  template:
    spec:
      replicatedJobs:
        - name: trainer
          replicas: 1
          template:
            spec:
              parallelism: 2
              completions: 2
              template:
                spec:
                  schedulerName: kai-scheduler
                  containers:
                    - name: trainer
                      image: nvcr.io/nvidia/pytorch:25.12-py3
                      env:
                        - name: NCCL_DEBUG
                          value: "INFO"
                        - name: NCCL_IB_DISABLE
                          value: "1"
                        - name: NCCL_SOCKET_IFNAME
                          value: "eth0"
                      resources:
                        requests:
                          cpu: "4"
                          memory: "16Gi"
                          nvidia.com/gpu: "1"
                        limits:
                          cpu: "8"
                          memory: "32Gi"
                          nvidia.com/gpu: "1"
                      volumeMounts:
                        - name: shm
                          mountPath: /dev/shm
                        - name: scripts
                          mountPath: /workspace
                        - name: storage
                          mountPath: /mnt/storage
                  volumes:
                    - name: shm
                      emptyDir:
                        medium: Memory
                        sizeLimit: 8Gi
                    - name: scripts
                      configMap:
                        name: mnist-train-script
                    - name: storage
                      persistentVolumeClaim:
                        claimName: mnist-pipeline-storage
                  restartPolicy: OnFailure

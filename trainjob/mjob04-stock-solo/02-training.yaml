---
apiVersion: trainer.kubeflow.org/v1alpha1
kind: TrainingRuntime
metadata:
  name: stock-runtime
  namespace: mlteam
spec:
  mlPolicy:
    numNodes: 1
    torch:
      numProcPerNode: auto
  template:
    spec:
      replicatedJobs:
        - name: trainer
          replicas: 1
          template:
            spec:
              parallelism: 1
              completions: 1
              template:
                spec:
                  schedulerName: kai-scheduler
                  initContainers:
                    - name: git-clone
                      image: alpine/git
                      command:
                        - sh
                        - -c
                        - |
                          git clone --depth=1 https://github.com/ds2qdu/train-model.git /workspace/repo
                          cp /workspace/repo/trainjob/mjob04-stock/train.py /workspace/train.py
                          echo "Git clone completed"
                          ls -la /workspace/
                      volumeMounts:
                        - name: workspace
                          mountPath: /workspace
                  containers:
                    - name: trainer
                      image: nvcr.io/nvidia/pytorch:25.12-py3
                      command:
                        - bash
                        - -c
                        - |
                          # Install dependencies
                          echo "=== Installing dependencies ==="
                          pip install --root-user-action=ignore yfinance scikit-learn transformers chromadb onnxscript pytz tensorboard
                          echo "=== Dependencies installed successfully ==="

                          # Environment setup (single node, single GPU)
                          export WORLD_SIZE=1
                          export RANK=0
                          export MASTER_PORT=29500
                          export LOCAL_RANK=0
                          export MASTER_ADDR=localhost

                          echo "=== Environment ==="
                          echo "WORLD_SIZE=$WORLD_SIZE"
                          echo "RANK=$RANK"
                          echo "MASTER_ADDR=$MASTER_ADDR"
                          echo "MASTER_PORT=$MASTER_PORT"
                          echo ""

                          torchrun \
                            --nnodes=1 \
                            --nproc_per_node=1 \
                            --node_rank=0 \
                            --master_addr=localhost \
                            --master_port=$MASTER_PORT \
                            /workspace/train.py \
                            --epochs=100 \
                            --batch-size=32 \
                            --lr=0.0001 \
                            --seq-length=30 \
                            --pred-length=5 \
                            --d-model=256 \
                            --nhead=8 \
                            --num-layers=4 \
                            --data-dir=/mnt/storage/data \
                            --checkpoint-dir=/mnt/storage/checkpoints \
                            --export-dir=/mnt/storage/models \
                            --chromadb-dir=/mnt/storage/chromadb \
                            --tensorboard-dir=/mnt/tensorboard 
                            # --tensorboard-dir=/mnt/tensorboard \
                            # --resume
                      env:
                        - name: NCCL_DEBUG
                          value: "INFO"
                        - name: NCCL_IB_DISABLE
                          value: "1"
                        - name: NCCL_SOCKET_IFNAME
                          value: "eth0"
                        - name: NCCL_NET
                          value: "Socket"
                        - name: FINNHUB_API_KEY
                          valueFrom:
                            secretKeyRef:
                              name: finnhub-secret
                              key: api-key
                        - name: HF_HOME
                          value: "/mnt/storage/huggingface"
                        - name: TOKENIZERS_PARALLELISM
                          value: "false"
                        - name: PIP_USE_FEATURE
                          value: "build-constraint"
                      resources:
                        requests:
                          cpu: "4"
                          memory: "16Gi"
                          nvidia.com/gpu: "1"
                        limits:
                          cpu: "8"
                          memory: "32Gi"
                          nvidia.com/gpu: "1"
                      volumeMounts:
                        - name: shm
                          mountPath: /dev/shm
                        - name: workspace
                          mountPath: /workspace
                        - name: storage
                          mountPath: /mnt/storage
                        - name: tensorboard-volume
                          mountPath: /mnt/tensorboard
                  volumes:
                    - name: shm
                      emptyDir:
                        medium: Memory
                        sizeLimit: 8Gi
                    - name: workspace
                      emptyDir: {}
                    - name: storage
                      persistentVolumeClaim:
                        claimName: stock-pipeline-storage
                    - name: tensorboard-volume
                      persistentVolumeClaim:
                        claimName: stock-tensorboard-storage
                  restartPolicy: OnFailure
---
apiVersion: trainer.kubeflow.org/v1alpha1
kind: TrainJob
metadata:
  name: stock-training-tensorboard
  namespace: mlteam
  annotations:
    kai.scheduler/queue: "mlteam-queue"
spec:
  runtimeRef:
    name: stock-runtime
    kind: TrainingRuntime
    apiGroup: trainer.kubeflow.org
  trainer:
    image: nvcr.io/nvidia/pytorch:25.12-py3
    numNodes: 1
    numProcPerNode: 1
    resourcesPerNode:
      requests:
        cpu: "4"
        memory: "16Gi"
        nvidia.com/gpu: "1"
      limits:
        cpu: "8"
        memory: "32Gi"
        nvidia.com/gpu: "1"
    env:
      - name: NCCL_DEBUG
        value: "INFO"
      - name: NCCL_IB_DISABLE
        value: "1"
      - name: NCCL_SOCKET_IFNAME
        value: "eth0"
      - name: NCCL_NET
        value: "Socket"
  podTemplateOverrides:
    - targetJobs:
        - name: trainer
      spec:
        tolerations:
          - key: "nvidia.com/gpu"
            operator: "Equal"
            value: "true"
            effect: "NoSchedule"

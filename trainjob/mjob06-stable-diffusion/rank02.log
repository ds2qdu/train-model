=== Installing Stable Diffusion dependencies ===
Collecting transformers
  Downloading transformers-5.0.0-py3-none-any.whl.metadata (37 kB)
Collecting accelerate
  Downloading accelerate-1.12.0-py3-none-any.whl.metadata (19 kB)
Requirement already satisfied: safetensors in /usr/local/lib/python3.12/dist-packages (0.7.0)
Collecting peft
  Downloading peft-0.18.1-py3-none-any.whl.metadata (14 kB)
Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.4.1)
Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (12.0.0)
Collecting ftfy
  Downloading ftfy-6.3.1-py3-none-any.whl.metadata (7.3 kB)
Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.1)
Collecting diffusers[torch]
  Downloading diffusers-0.36.0-py3-none-any.whl.metadata (20 kB)
Requirement already satisfied: importlib_metadata in /usr/local/lib/python3.12/dist-packages (from diffusers[torch]) (8.7.0)
Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from diffusers[torch]) (3.20.1)
Requirement already satisfied: httpx<1.0.0 in /usr/local/lib/python3.12/dist-packages (from diffusers[torch]) (0.28.1)
Requirement already satisfied: huggingface-hub<2.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from diffusers[torch]) (1.2.3)
Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from diffusers[torch]) (2.1.0)
Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from diffusers[torch]) (2025.11.3)
Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from diffusers[torch]) (2.32.5)
Requirement already satisfied: torch>=1.4 in /usr/local/lib/python3.12/dist-packages (from diffusers[torch]) (2.10.0a0+b4e4ee81d3.nv25.12)
Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->diffusers[torch]) (4.12.0)
Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->diffusers[torch]) (2025.11.12)
Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->diffusers[torch]) (1.0.9)
Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->diffusers[torch]) (3.11)
Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0.0->diffusers[torch]) (0.16.0)
Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.34.0->diffusers[torch]) (2025.10.0)
Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.34.0->diffusers[torch]) (1.2.0)
Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.34.0->diffusers[torch]) (25.0)
Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.34.0->diffusers[torch]) (6.0.3)
Requirement already satisfied: shellingham in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.34.0->diffusers[torch]) (1.5.4)
Requirement already satisfied: typer-slim in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.34.0->diffusers[torch]) (0.20.0)
Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.34.0->diffusers[torch]) (4.15.0)
Collecting huggingface-hub<2.0,>=0.34.0 (from diffusers[torch])
  Downloading huggingface_hub-1.3.5-py3-none-any.whl.metadata (13 kB)
Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)
Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate) (7.1.3)
Requirement already satisfied: pyarrow>=21.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (22.0.0)
Requirement already satisfied: dill<0.4.1,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.4.0)
Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets) (2.3.3)
Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.6.0)
Requirement already satisfied: multiprocess<0.70.19 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.18)
Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (3.13.2)
Requirement already satisfied: wcwidth in /usr/local/lib/python3.12/dist-packages (from ftfy) (0.2.14)
Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2.6.1)
Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.4.0)
Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (25.4.0)
Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.8.0)
Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (6.7.0)
Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (0.4.1)
Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.22.0)
Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->diffusers[torch]) (3.4.4)
Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->diffusers[torch]) (2.6.1)
Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.4->diffusers[torch]) (80.9.0)
Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.4->diffusers[torch]) (1.14.0)
Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.4->diffusers[torch]) (3.6.1)
Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.4->diffusers[torch]) (3.1.6)
Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.4->diffusers[torch]) (1.3.0)
Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib_metadata->diffusers[torch]) (3.23.0)
Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.4->diffusers[torch]) (3.0.3)
Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2.9.0.post0)
Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)
Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.3)
Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)
Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer-slim->huggingface-hub<2.0,>=0.34.0->diffusers[torch]) (8.3.1)
Downloading diffusers-0.36.0-py3-none-any.whl (4.6 MB)
   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 4.6/4.6 MB 18.8 MB/s  0:00:00
Downloading transformers-5.0.0-py3-none-any.whl (10.1 MB)
   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 10.1/10.1 MB 79.9 MB/s  0:00:00
Downloading huggingface_hub-1.3.5-py3-none-any.whl (536 kB)
   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 536.7/536.7 kB 23.8 MB/s  0:00:00
Downloading accelerate-1.12.0-py3-none-any.whl (380 kB)
Downloading peft-0.18.1-py3-none-any.whl (556 kB)
   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 557.0/557.0 kB 26.5 MB/s  0:00:00
Downloading ftfy-6.3.1-py3-none-any.whl (44 kB)
Installing collected packages: ftfy, huggingface-hub, diffusers, accelerate, transformers, peft
  Attempting uninstall: huggingface-hub
    Found existing installation: huggingface_hub 1.2.3
    Uninstalling huggingface_hub-1.2.3:
      Successfully uninstalled huggingface_hub-1.2.3

Successfully installed accelerate-1.12.0 diffusers-0.36.0 ftfy-6.3.1 huggingface-hub-1.3.5 peft-0.18.1 transformers-5.0.0
Waiting for master pod...
Found master: 10.0.4.118
=== Distributed Training Config ===
WORLD_SIZE: 2
RANK: 1
MASTER_ADDR: 10.0.4.118
MASTER_PORT: 29500
MY_IP: 10.0.5.42
=== GPU Information ===
Mon Feb  2 01:47:30 2026       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 580.95.05              Driver Version: 580.95.05      CUDA Version: 13.1     |
+-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA GB10                    On  |   0000000F:01:00.0 Off |                  N/A |
| N/A   35C    P8              5W /  N/A  | Not Supported          |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+

+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+
Waiting for master port...
Master is ready!
=== Starting Distributed Stable Diffusion Fine-tuning ===
/usr/local/lib/python3.12/dist-packages/torch/library.py:356: UserWarning: Warning only once for all operators,  other operators may also be overridden.
  Overriding a previously registered kernel for the same operator and the same dispatch key
  operator: flash_attn::_flash_attn_backward(Tensor dout, Tensor q, Tensor k, Tensor v, Tensor out, Tensor softmax_lse, Tensor(a6!)? dq, Tensor(a7!)? dk, Tensor(a8!)? dv, float dropout_p, float softmax_scale, bool causal, SymInt window_size_left, SymInt window_size_right, float softcap, Tensor? alibi_slopes, bool deterministic, Tensor? rng_state=None) -> Tensor
    registered at /usr/local/lib/python3.12/dist-packages/torch/_library/custom_ops.py:922
  dispatch key: ADInplaceOrView
  previous kernel: no debug info
       new kernel: registered at /usr/local/lib/python3.12/dist-packages/torch/_library/custom_ops.py:922 (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/core/dispatch/OperatorEntry.cpp:208.)
  self.m.impl(
Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.
Loading pipeline components...:   0%|          | 0/6 [00:00<?, ?it/s]Loading pipeline components...:  17%|â–ˆâ–‹        | 1/6 [02:57<14:49, 177.95s/it]
Loading weights:   0%|          | 0/196 [00:00<?, ?it/s][A
Loading weights:   1%|          | 1/196 [00:00<00:00, 13981.01it/s, Materializing param=text_model.embeddings.position_embedding.weight][A
Loading weights:   1%|          | 1/196 [00:00<00:00, 3785.47it/s, Materializing param=text_model.embeddings.position_embedding.weight] [A
Loading weights:   1%|          | 2/196 [00:00<00:00, 4728.64it/s, Materializing param=text_model.embeddings.token_embedding.weight]   [A
Loading weights:   1%|          | 2/196 [00:00<00:00, 3381.14it/s, Materializing param=text_model.embeddings.token_embedding.weight][A
Loading weights:   2%|â–         | 3/196 [00:25<26:55,  8.37s/it, Materializing param=text_model.embeddings.token_embedding.weight]  [A
Loading weights:   2%|â–         | 3/196 [00:25<26:55,  8.37s/it, Materializing param=text_model.encoder.layers.0.layer_norm1.bias][A
Loading weights:   2%|â–         | 3/196 [00:25<26:55,  8.37s/it, Materializing param=text_model.encoder.layers.0.layer_norm1.bias][A
Loading weights:   2%|â–         | 4/196 [00:25<26:47,  8.37s/it, Materializing param=text_model.encoder.layers.0.layer_norm1.weight][A
Loading weights:   2%|â–         | 4/196 [00:25<26:47,  8.37s/it, Materializing param=text_model.encoder.layers.0.layer_norm1.weight][A
Loading weights:   3%|â–Ž         | 5/196 [00:25<26:38,  8.37s/it, Materializing param=text_model.encoder.layers.0.layer_norm2.bias]  [A
Loading weights:   3%|â–Ž         | 5/196 [00:25<26:38,  8.37s/it, Materializing param=text_model.encoder.layers.0.layer_norm2.bias][A
Loading weights:   3%|â–Ž         | 6/196 [00:25<26:30,  8.37s/it, Materializing param=text_model.encoder.layers.0.layer_norm2.weight][A
Loading weights:   3%|â–Ž         | 6/196 [00:25<26:30,  8.37s/it, Materializing param=text_model.encoder.layers.0.layer_norm2.weight][A
Loading weights:   4%|â–Ž         | 7/196 [00:25<26:22,  8.37s/it, Materializing param=text_model.encoder.layers.0.mlp.fc1.bias]      [A
Loading weights:   4%|â–Ž         | 7/196 [00:25<26:22,  8.37s/it, Materializing param=text_model.encoder.layers.0.mlp.fc1.bias][A
Loading weights:   4%|â–         | 8/196 [00:25<26:13,  8.37s/it, Materializing param=text_model.encoder.layers.0.mlp.fc1.weight][A
Loading weights:   4%|â–         | 8/196 [00:25<26:13,  8.37s/it, Materializing param=text_model.encoder.layers.0.mlp.fc1.weight][A
Loading weights:   5%|â–         | 9/196 [00:25<26:05,  8.37s/it, Materializing param=text_model.encoder.layers.0.mlp.fc2.bias]  [A
Loading weights:   5%|â–         | 9/196 [00:25<26:05,  8.37s/it, Materializing param=text_model.encoder.layers.0.mlp.fc2.bias][A
Loading weights:   5%|â–Œ         | 10/196 [00:25<25:56,  8.37s/it, Materializing param=text_model.encoder.layers.0.mlp.fc2.weight][A
Loading weights:   5%|â–Œ         | 10/196 [00:25<25:56,  8.37s/it, Materializing param=text_model.encoder.layers.0.mlp.fc2.weight][A
Loading weights:   6%|â–Œ         | 11/196 [00:25<25:48,  8.37s/it, Materializing param=text_model.encoder.layers.0.self_attn.k_proj.bias][A
Loading weights:   6%|â–Œ         | 11/196 [00:25<25:48,  8.37s/it, Materializing param=text_model.encoder.layers.0.self_attn.k_proj.bias][A
Loading weights:   6%|â–Œ         | 12/196 [00:25<25:40,  8.37s/it, Materializing param=text_model.encoder.layers.0.self_attn.k_proj.weight][A
Loading weights:   6%|â–Œ         | 12/196 [00:25<25:40,  8.37s/it, Materializing param=text_model.encoder.layers.0.self_attn.k_proj.weight][A
Loading weights:   7%|â–‹         | 13/196 [00:25<25:31,  8.37s/it, Materializing param=text_model.encoder.layers.0.self_attn.out_proj.bias][A
Loading weights:   7%|â–‹         | 13/196 [00:25<25:31,  8.37s/it, Materializing param=text_model.encoder.layers.0.self_attn.out_proj.bias][A
Loading weights:   7%|â–‹         | 14/196 [00:25<25:23,  8.37s/it, Materializing param=text_model.encoder.layers.0.self_attn.out_proj.weight][A
Loading weights:   7%|â–‹         | 14/196 [00:25<25:23,  8.37s/it, Materializing param=text_model.encoder.layers.0.self_attn.out_proj.weight][A
Loading weights:   8%|â–Š         | 15/196 [00:25<25:15,  8.37s/it, Materializing param=text_model.encoder.layers.0.self_attn.q_proj.bias]    [A
Loading weights:   8%|â–Š         | 15/196 [00:25<25:15,  8.37s/it, Materializing param=text_model.encoder.layers.0.self_attn.q_proj.bias][A
Loading weights:   8%|â–Š         | 16/196 [00:25<25:06,  8.37s/it, Materializing param=text_model.encoder.layers.0.self_attn.q_proj.weight][A
Loading weights:   8%|â–Š         | 16/196 [00:25<25:06,  8.37s/it, Materializing param=text_model.encoder.layers.0.self_attn.q_proj.weight][A
Loading weights:   9%|â–Š         | 17/196 [00:25<24:58,  8.37s/it, Materializing param=text_model.encoder.layers.0.self_attn.v_proj.bias]  [A
Loading weights:   9%|â–Š         | 17/196 [00:25<24:58,  8.37s/it, Materializing param=text_model.encoder.layers.0.self_attn.v_proj.bias][A
Loading weights:   9%|â–‰         | 18/196 [00:25<24:50,  8.37s/it, Materializing param=text_model.encoder.layers.0.self_attn.v_proj.weight][A
Loading weights:   9%|â–‰         | 18/196 [00:25<24:50,  8.37s/it, Materializing param=text_model.encoder.layers.0.self_attn.v_proj.weight][A
Loading weights:  10%|â–‰         | 19/196 [00:25<24:41,  8.37s/it, Materializing param=text_model.encoder.layers.1.layer_norm1.bias]       [A
Loading weights:  10%|â–‰         | 19/196 [00:25<24:41,  8.37s/it, Materializing param=text_model.encoder.layers.1.layer_norm1.bias][A
Loading weights:  10%|â–ˆ         | 20/196 [00:25<24:33,  8.37s/it, Materializing param=text_model.encoder.layers.1.layer_norm1.weight][A
Loading weights:  10%|â–ˆ         | 20/196 [00:25<24:33,  8.37s/it, Materializing param=text_model.encoder.layers.1.layer_norm1.weight][A
Loading weights:  11%|â–ˆ         | 21/196 [00:25<24:24,  8.37s/it, Materializing param=text_model.encoder.layers.1.layer_norm2.bias]  [A
Loading weights:  11%|â–ˆ         | 21/196 [00:25<24:24,  8.37s/it, Materializing param=text_model.encoder.layers.1.layer_norm2.bias][A
Loading weights:  11%|â–ˆ         | 22/196 [00:25<24:16,  8.37s/it, Materializing param=text_model.encoder.layers.1.layer_norm2.weight][A
Loading weights:  11%|â–ˆ         | 22/196 [00:25<24:16,  8.37s/it, Materializing param=text_model.encoder.layers.1.layer_norm2.weight][A
Loading weights:  12%|â–ˆâ–        | 23/196 [00:25<24:08,  8.37s/it, Materializing param=text_model.encoder.layers.1.mlp.fc1.bias]      [A
Loading weights:  12%|â–ˆâ–        | 23/196 [00:25<24:08,  8.37s/it, Materializing param=text_model.encoder.layers.1.mlp.fc1.bias][A
Loading weights:  12%|â–ˆâ–        | 24/196 [00:25<23:59,  8.37s/it, Materializing param=text_model.encoder.layers.1.mlp.fc1.weight][A
Loading weights:  12%|â–ˆâ–        | 24/196 [00:25<23:59,  8.37s/it, Materializing param=text_model.encoder.layers.1.mlp.fc1.weight][A
Loading weights:  13%|â–ˆâ–Ž        | 25/196 [00:25<23:51,  8.37s/it, Materializing param=text_model.encoder.layers.1.mlp.fc2.bias]  [A
Loading weights:  13%|â–ˆâ–Ž        | 25/196 [00:25<23:51,  8.37s/it, Materializing param=text_model.encoder.layers.1.mlp.fc2.bias][A
Loading weights:  13%|â–ˆâ–Ž        | 26/196 [00:25<23:43,  8.37s/it, Materializing param=text_model.encoder.layers.1.mlp.fc2.weight][A
Loading weights:  13%|â–ˆâ–Ž        | 26/196 [00:25<23:43,  8.37s/it, Materializing param=text_model.encoder.layers.1.mlp.fc2.weight][A
Loading weights:  14%|â–ˆâ–        | 27/196 [00:25<23:34,  8.37s/it, Materializing param=text_model.encoder.layers.1.self_attn.k_proj.bias][A
Loading weights:  14%|â–ˆâ–        | 27/196 [00:25<23:34,  8.37s/it, Materializing param=text_model.encoder.layers.1.self_attn.k_proj.bias][A
Loading weights:  14%|â–ˆâ–        | 28/196 [00:25<23:26,  8.37s/it, Materializing param=text_model.encoder.layers.1.self_attn.k_proj.weight][A
Loading weights:  14%|â–ˆâ–        | 28/196 [00:25<23:26,  8.37s/it, Materializing param=text_model.encoder.layers.1.self_attn.k_proj.weight][A
Loading weights:  15%|â–ˆâ–        | 29/196 [00:25<23:17,  8.37s/it, Materializing param=text_model.encoder.layers.1.self_attn.out_proj.bias][A
Loading weights:  15%|â–ˆâ–        | 29/196 [00:25<23:17,  8.37s/it, Materializing param=text_model.encoder.layers.1.self_attn.out_proj.bias][A
Loading weights:  15%|â–ˆâ–Œ        | 30/196 [00:25<23:09,  8.37s/it, Materializing param=text_model.encoder.layers.1.self_attn.out_proj.weight][A
Loading weights:  15%|â–ˆâ–Œ        | 30/196 [00:25<23:09,  8.37s/it, Materializing param=text_model.encoder.layers.1.self_attn.out_proj.weight][A
Loading weights:  16%|â–ˆâ–Œ        | 31/196 [00:25<23:01,  8.37s/it, Materializing param=text_model.encoder.layers.1.self_attn.q_proj.bias]    [A
Loading weights:  16%|â–ˆâ–Œ        | 31/196 [00:25<23:01,  8.37s/it, Materializing param=text_model.encoder.layers.1.self_attn.q_proj.bias][A
Loading weights:  16%|â–ˆâ–‹        | 32/196 [00:25<22:52,  8.37s/it, Materializing param=text_model.encoder.layers.1.self_attn.q_proj.weight][A
Loading weights:  16%|â–ˆâ–‹        | 32/196 [00:25<22:52,  8.37s/it, Materializing param=text_model.encoder.layers.1.self_attn.q_proj.weight][A
Loading weights:  17%|â–ˆâ–‹        | 33/196 [00:25<22:44,  8.37s/it, Materializing param=text_model.encoder.layers.1.self_attn.v_proj.bias]  [A
Loading weights:  17%|â–ˆâ–‹        | 33/196 [00:25<22:44,  8.37s/it, Materializing param=text_model.encoder.layers.1.self_attn.v_proj.bias][A
Loading weights:  17%|â–ˆâ–‹        | 34/196 [00:25<22:36,  8.37s/it, Materializing param=text_model.encoder.layers.1.self_attn.v_proj.weight][A
Loading weights:  17%|â–ˆâ–‹        | 34/196 [00:25<22:36,  8.37s/it, Materializing param=text_model.encoder.layers.1.self_attn.v_proj.weight][A
Loading weights:  18%|â–ˆâ–Š        | 35/196 [00:25<22:27,  8.37s/it, Materializing param=text_model.encoder.layers.2.layer_norm1.bias]       [A
Loading weights:  18%|â–ˆâ–Š        | 35/196 [00:25<22:27,  8.37s/it, Materializing param=text_model.encoder.layers.2.layer_norm1.bias][A
Loading weights:  18%|â–ˆâ–Š        | 36/196 [00:25<22:19,  8.37s/it, Materializing param=text_model.encoder.layers.2.layer_norm1.weight][A
Loading weights:  18%|â–ˆâ–Š        | 36/196 [00:25<22:19,  8.37s/it, Materializing param=text_model.encoder.layers.2.layer_norm1.weight][A
Loading weights:  19%|â–ˆâ–‰        | 37/196 [00:25<22:10,  8.37s/it, Materializing param=text_model.encoder.layers.2.layer_norm2.bias]  [A
Loading weights:  19%|â–ˆâ–‰        | 37/196 [00:25<22:10,  8.37s/it, Materializing param=text_model.encoder.layers.2.layer_norm2.bias][A
Loading weights:  19%|â–ˆâ–‰        | 38/196 [00:25<22:02,  8.37s/it, Materializing param=text_model.encoder.layers.2.layer_norm2.weight][A
Loading weights:  19%|â–ˆâ–‰        | 38/196 [00:25<22:02,  8.37s/it, Materializing param=text_model.encoder.layers.2.layer_norm2.weight][A
Loading weights:  20%|â–ˆâ–‰        | 39/196 [00:25<21:54,  8.37s/it, Materializing param=text_model.encoder.layers.2.mlp.fc1.bias]      [A
Loading weights:  20%|â–ˆâ–‰        | 39/196 [00:25<21:54,  8.37s/it, Materializing param=text_model.encoder.layers.2.mlp.fc1.bias][A
Loading weights:  20%|â–ˆâ–ˆ        | 40/196 [00:25<21:45,  8.37s/it, Materializing param=text_model.encoder.layers.2.mlp.fc1.weight][A
Loading weights:  20%|â–ˆâ–ˆ        | 40/196 [00:25<21:45,  8.37s/it, Materializing param=text_model.encoder.layers.2.mlp.fc1.weight][A
Loading weights:  21%|â–ˆâ–ˆ        | 41/196 [00:25<21:37,  8.37s/it, Materializing param=text_model.encoder.layers.2.mlp.fc2.bias]  [A
Loading weights:  21%|â–ˆâ–ˆ        | 41/196 [00:25<21:37,  8.37s/it, Materializing param=text_model.encoder.layers.2.mlp.fc2.bias][A
Loading weights:  21%|â–ˆâ–ˆâ–       | 42/196 [00:25<21:29,  8.37s/it, Materializing param=text_model.encoder.layers.2.mlp.fc2.weight][A
Loading weights:  21%|â–ˆâ–ˆâ–       | 42/196 [00:25<21:29,  8.37s/it, Materializing param=text_model.encoder.layers.2.mlp.fc2.weight][A
Loading weights:  22%|â–ˆâ–ˆâ–       | 43/196 [00:25<21:20,  8.37s/it, Materializing param=text_model.encoder.layers.2.self_attn.k_proj.bias][A
Loading weights:  22%|â–ˆâ–ˆâ–       | 43/196 [00:25<21:20,  8.37s/it, Materializing param=text_model.encoder.layers.2.self_attn.k_proj.bias][A
Loading weights:  22%|â–ˆâ–ˆâ–       | 44/196 [00:25<21:12,  8.37s/it, Materializing param=text_model.encoder.layers.2.self_attn.k_proj.weight][A
Loading weights:  22%|â–ˆâ–ˆâ–       | 44/196 [00:25<21:12,  8.37s/it, Materializing param=text_model.encoder.layers.2.self_attn.k_proj.weight][A
Loading weights:  23%|â–ˆâ–ˆâ–Ž       | 45/196 [00:25<21:03,  8.37s/it, Materializing param=text_model.encoder.layers.2.self_attn.out_proj.bias][A
Loading weights:  23%|â–ˆâ–ˆâ–Ž       | 45/196 [00:25<21:03,  8.37s/it, Materializing param=text_model.encoder.layers.2.self_attn.out_proj.bias][A
Loading weights:  23%|â–ˆâ–ˆâ–Ž       | 46/196 [00:25<20:55,  8.37s/it, Materializing param=text_model.encoder.layers.2.self_attn.out_proj.weight][A
Loading weights:  23%|â–ˆâ–ˆâ–Ž       | 46/196 [00:25<20:55,  8.37s/it, Materializing param=text_model.encoder.layers.2.self_attn.out_proj.weight][A
Loading weights:  24%|â–ˆâ–ˆâ–       | 47/196 [00:25<20:47,  8.37s/it, Materializing param=text_model.encoder.layers.2.self_attn.q_proj.bias]    [A
Loading weights:  24%|â–ˆâ–ˆâ–       | 47/196 [00:25<20:47,  8.37s/it, Materializing param=text_model.encoder.layers.2.self_attn.q_proj.bias][A
Loading weights:  24%|â–ˆâ–ˆâ–       | 48/196 [00:25<20:38,  8.37s/it, Materializing param=text_model.encoder.layers.2.self_attn.q_proj.weight][A
Loading weights:  24%|â–ˆâ–ˆâ–       | 48/196 [00:25<20:38,  8.37s/it, Materializing param=text_model.encoder.layers.2.self_attn.q_proj.weight][A
Loading weights:  25%|â–ˆâ–ˆâ–Œ       | 49/196 [00:25<20:30,  8.37s/it, Materializing param=text_model.encoder.layers.2.self_attn.v_proj.bias]  [A
Loading weights:  25%|â–ˆâ–ˆâ–Œ       | 49/196 [00:25<20:30,  8.37s/it, Materializing param=text_model.encoder.layers.2.self_attn.v_proj.bias][A
Loading weights:  26%|â–ˆâ–ˆâ–Œ       | 50/196 [00:25<20:22,  8.37s/it, Materializing param=text_model.encoder.layers.2.self_attn.v_proj.weight][A
Loading weights:  26%|â–ˆâ–ˆâ–Œ       | 50/196 [00:25<20:22,  8.37s/it, Materializing param=text_model.encoder.layers.2.self_attn.v_proj.weight][A
Loading weights:  26%|â–ˆâ–ˆâ–Œ       | 51/196 [00:25<20:13,  8.37s/it, Materializing param=text_model.encoder.layers.3.layer_norm1.bias]       [A
Loading weights:  26%|â–ˆâ–ˆâ–Œ       | 51/196 [00:25<20:13,  8.37s/it, Materializing param=text_model.encoder.layers.3.layer_norm1.bias][A
Loading weights:  27%|â–ˆâ–ˆâ–‹       | 52/196 [00:25<20:05,  8.37s/it, Materializing param=text_model.encoder.layers.3.layer_norm1.weight][A
Loading weights:  27%|â–ˆâ–ˆâ–‹       | 52/196 [00:25<20:05,  8.37s/it, Materializing param=text_model.encoder.layers.3.layer_norm1.weight][A
Loading weights:  27%|â–ˆâ–ˆâ–‹       | 53/196 [00:25<19:57,  8.37s/it, Materializing param=text_model.encoder.layers.3.layer_norm2.bias]  [A
Loading weights:  27%|â–ˆâ–ˆâ–‹       | 53/196 [00:25<19:57,  8.37s/it, Materializing param=text_model.encoder.layers.3.layer_norm2.bias][A
Loading weights:  28%|â–ˆâ–ˆâ–Š       | 54/196 [00:25<19:48,  8.37s/it, Materializing param=text_model.encoder.layers.3.layer_norm2.weight][A
Loading weights:  28%|â–ˆâ–ˆâ–Š       | 54/196 [00:25<19:48,  8.37s/it, Materializing param=text_model.encoder.layers.3.layer_norm2.weight][A
Loading weights:  28%|â–ˆâ–ˆâ–Š       | 55/196 [00:25<19:40,  8.37s/it, Materializing param=text_model.encoder.layers.3.mlp.fc1.bias]      [A
Loading weights:  28%|â–ˆâ–ˆâ–Š       | 55/196 [00:25<19:40,  8.37s/it, Materializing param=text_model.encoder.layers.3.mlp.fc1.bias][A
Loading weights:  29%|â–ˆâ–ˆâ–Š       | 56/196 [00:25<19:31,  8.37s/it, Materializing param=text_model.encoder.layers.3.mlp.fc1.weight][A
Loading weights:  29%|â–ˆâ–ˆâ–Š       | 56/196 [00:25<19:31,  8.37s/it, Materializing param=text_model.encoder.layers.3.mlp.fc1.weight][A
Loading weights:  29%|â–ˆâ–ˆâ–‰       | 57/196 [00:25<19:23,  8.37s/it, Materializing param=text_model.encoder.layers.3.mlp.fc2.bias]  [A
Loading weights:  29%|â–ˆâ–ˆâ–‰       | 57/196 [00:25<19:23,  8.37s/it, Materializing param=text_model.encoder.layers.3.mlp.fc2.bias][A
Loading weights:  30%|â–ˆâ–ˆâ–‰       | 58/196 [00:25<19:15,  8.37s/it, Materializing param=text_model.encoder.layers.3.mlp.fc2.weight][A
Loading weights:  30%|â–ˆâ–ˆâ–‰       | 58/196 [00:25<19:15,  8.37s/it, Materializing param=text_model.encoder.layers.3.mlp.fc2.weight][A
Loading weights:  30%|â–ˆâ–ˆâ–ˆ       | 59/196 [00:25<19:06,  8.37s/it, Materializing param=text_model.encoder.layers.3.self_attn.k_proj.bias][A
Loading weights:  30%|â–ˆâ–ˆâ–ˆ       | 59/196 [00:25<19:06,  8.37s/it, Materializing param=text_model.encoder.layers.3.self_attn.k_proj.bias][A
Loading weights:  31%|â–ˆâ–ˆâ–ˆ       | 60/196 [00:25<18:58,  8.37s/it, Materializing param=text_model.encoder.layers.3.self_attn.k_proj.weight][A
Loading weights:  31%|â–ˆâ–ˆâ–ˆ       | 60/196 [00:25<18:58,  8.37s/it, Materializing param=text_model.encoder.layers.3.self_attn.k_proj.weight][A
Loading weights:  31%|â–ˆâ–ˆâ–ˆ       | 61/196 [00:25<18:50,  8.37s/it, Materializing param=text_model.encoder.layers.3.self_attn.out_proj.bias][A
Loading weights:  31%|â–ˆâ–ˆâ–ˆ       | 61/196 [00:25<18:50,  8.37s/it, Materializing param=text_model.encoder.layers.3.self_attn.out_proj.bias][A
Loading weights:  32%|â–ˆâ–ˆâ–ˆâ–      | 62/196 [00:25<18:41,  8.37s/it, Materializing param=text_model.encoder.layers.3.self_attn.out_proj.weight][A
Loading weights:  32%|â–ˆâ–ˆâ–ˆâ–      | 62/196 [00:25<18:41,  8.37s/it, Materializing param=text_model.encoder.layers.3.self_attn.out_proj.weight][A
Loading weights:  32%|â–ˆâ–ˆâ–ˆâ–      | 63/196 [00:25<18:33,  8.37s/it, Materializing param=text_model.encoder.layers.3.self_attn.q_proj.bias]    [A
Loading weights:  32%|â–ˆâ–ˆâ–ˆâ–      | 63/196 [00:25<18:33,  8.37s/it, Materializing param=text_model.encoder.layers.3.self_attn.q_proj.bias][A
Loading weights:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 64/196 [00:25<18:24,  8.37s/it, Materializing param=text_model.encoder.layers.3.self_attn.q_proj.weight][A
Loading weights:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 64/196 [00:25<18:24,  8.37s/it, Materializing param=text_model.encoder.layers.3.self_attn.q_proj.weight][A
Loading weights:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 65/196 [00:25<18:16,  8.37s/it, Materializing param=text_model.encoder.layers.3.self_attn.v_proj.bias]  [A
Loading weights:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 65/196 [00:25<18:16,  8.37s/it, Materializing param=text_model.encoder.layers.3.self_attn.v_proj.bias][A
Loading weights:  34%|â–ˆâ–ˆâ–ˆâ–Ž      | 66/196 [00:25<18:08,  8.37s/it, Materializing param=text_model.encoder.layers.3.self_attn.v_proj.weight][A
Loading weights:  34%|â–ˆâ–ˆâ–ˆâ–Ž      | 66/196 [00:25<18:08,  8.37s/it, Materializing param=text_model.encoder.layers.3.self_attn.v_proj.weight][A
Loading weights:  34%|â–ˆâ–ˆâ–ˆâ–      | 67/196 [00:25<17:59,  8.37s/it, Materializing param=text_model.encoder.layers.4.layer_norm1.bias]       [A
Loading weights:  34%|â–ˆâ–ˆâ–ˆâ–      | 67/196 [00:25<17:59,  8.37s/it, Materializing param=text_model.encoder.layers.4.layer_norm1.bias][A
Loading weights:  35%|â–ˆâ–ˆâ–ˆâ–      | 68/196 [00:25<17:51,  8.37s/it, Materializing param=text_model.encoder.layers.4.layer_norm1.weight][A
Loading weights:  35%|â–ˆâ–ˆâ–ˆâ–      | 68/196 [00:25<17:51,  8.37s/it, Materializing param=text_model.encoder.layers.4.layer_norm1.weight][A
Loading weights:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 69/196 [00:25<17:43,  8.37s/it, Materializing param=text_model.encoder.layers.4.layer_norm2.bias]  [A
Loading weights:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 69/196 [00:25<17:43,  8.37s/it, Materializing param=text_model.encoder.layers.4.layer_norm2.bias][A
Loading weights:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 70/196 [00:25<17:34,  8.37s/it, Materializing param=text_model.encoder.layers.4.layer_norm2.weight][A
Loading weights:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 70/196 [00:25<17:34,  8.37s/it, Materializing param=text_model.encoder.layers.4.layer_norm2.weight][A
Loading weights:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 71/196 [00:25<17:26,  8.37s/it, Materializing param=text_model.encoder.layers.4.mlp.fc1.bias]      [A
Loading weights:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 71/196 [00:25<17:26,  8.37s/it, Materializing param=text_model.encoder.layers.4.mlp.fc1.bias][A
Loading weights:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 72/196 [00:25<17:17,  8.37s/it, Materializing param=text_model.encoder.layers.4.mlp.fc1.weight][A
Loading weights:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 72/196 [00:25<17:17,  8.37s/it, Materializing param=text_model.encoder.layers.4.mlp.fc1.weight][A
Loading weights:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 73/196 [00:25<17:09,  8.37s/it, Materializing param=text_model.encoder.layers.4.mlp.fc2.bias]  [A
Loading weights:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 73/196 [00:25<17:09,  8.37s/it, Materializing param=text_model.encoder.layers.4.mlp.fc2.bias][A
Loading weights:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 74/196 [00:25<17:01,  8.37s/it, Materializing param=text_model.encoder.layers.4.mlp.fc2.weight][A
Loading weights:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 74/196 [00:25<17:01,  8.37s/it, Materializing param=text_model.encoder.layers.4.mlp.fc2.weight][A
Loading weights:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 75/196 [00:25<16:52,  8.37s/it, Materializing param=text_model.encoder.layers.4.self_attn.k_proj.bias][A
Loading weights:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 75/196 [00:25<16:52,  8.37s/it, Materializing param=text_model.encoder.layers.4.self_attn.k_proj.bias][A
Loading weights:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 76/196 [00:25<16:44,  8.37s/it, Materializing param=text_model.encoder.layers.4.self_attn.k_proj.weight][A
Loading weights:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 76/196 [00:25<16:44,  8.37s/it, Materializing param=text_model.encoder.layers.4.self_attn.k_proj.weight][A
Loading weights:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 77/196 [00:25<16:36,  8.37s/it, Materializing param=text_model.encoder.layers.4.self_attn.out_proj.bias][A
Loading weights:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 77/196 [00:25<16:36,  8.37s/it, Materializing param=text_model.encoder.layers.4.self_attn.out_proj.bias][A
Loading weights:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 78/196 [00:25<16:27,  8.37s/it, Materializing param=text_model.encoder.layers.4.self_attn.out_proj.weight][A
Loading weights:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 78/196 [00:25<16:27,  8.37s/it, Materializing param=text_model.encoder.layers.4.self_attn.out_proj.weight][A
Loading weights:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 79/196 [00:25<16:19,  8.37s/it, Materializing param=text_model.encoder.layers.4.self_attn.q_proj.bias]    [A
Loading weights:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 79/196 [00:25<16:19,  8.37s/it, Materializing param=text_model.encoder.layers.4.self_attn.q_proj.bias][A
Loading weights:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 80/196 [00:25<16:11,  8.37s/it, Materializing param=text_model.encoder.layers.4.self_attn.q_proj.weight][A
Loading weights:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 80/196 [00:25<16:11,  8.37s/it, Materializing param=text_model.encoder.layers.4.self_attn.q_proj.weight][A
Loading weights:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 81/196 [00:25<16:02,  8.37s/it, Materializing param=text_model.encoder.layers.4.self_attn.v_proj.bias]  [A
Loading weights:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 81/196 [00:25<16:02,  8.37s/it, Materializing param=text_model.encoder.layers.4.self_attn.v_proj.bias][A
Loading weights:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 82/196 [00:25<15:54,  8.37s/it, Materializing param=text_model.encoder.layers.4.self_attn.v_proj.weight][A
Loading weights:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 82/196 [00:25<15:54,  8.37s/it, Materializing param=text_model.encoder.layers.4.self_attn.v_proj.weight][A
Loading weights:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 83/196 [00:25<15:45,  8.37s/it, Materializing param=text_model.encoder.layers.5.layer_norm1.bias]       [A
Loading weights:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 83/196 [00:25<15:45,  8.37s/it, Materializing param=text_model.encoder.layers.5.layer_norm1.bias][A
Loading weights:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 84/196 [00:25<15:37,  8.37s/it, Materializing param=text_model.encoder.layers.5.layer_norm1.weight][A
Loading weights:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 84/196 [00:25<15:37,  8.37s/it, Materializing param=text_model.encoder.layers.5.layer_norm1.weight][A
Loading weights:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 85/196 [00:25<15:29,  8.37s/it, Materializing param=text_model.encoder.layers.5.layer_norm2.bias]  [A
Loading weights:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 85/196 [00:25<15:29,  8.37s/it, Materializing param=text_model.encoder.layers.5.layer_norm2.bias][A
Loading weights:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 86/196 [00:25<15:20,  8.37s/it, Materializing param=text_model.encoder.layers.5.layer_norm2.weight][A
Loading weights:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 86/196 [00:25<15:20,  8.37s/it, Materializing param=text_model.encoder.layers.5.layer_norm2.weight][A
Loading weights:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 87/196 [00:25<15:12,  8.37s/it, Materializing param=text_model.encoder.layers.5.mlp.fc1.bias]      [A
Loading weights:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 87/196 [00:25<15:12,  8.37s/it, Materializing param=text_model.encoder.layers.5.mlp.fc1.bias][A
Loading weights:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 88/196 [00:25<15:04,  8.37s/it, Materializing param=text_model.encoder.layers.5.mlp.fc1.weight][A
Loading weights:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 88/196 [00:25<15:04,  8.37s/it, Materializing param=text_model.encoder.layers.5.mlp.fc1.weight][A
Loading weights:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 89/196 [00:25<14:55,  8.37s/it, Materializing param=text_model.encoder.layers.5.mlp.fc2.bias]  [A
Loading weights:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 89/196 [00:25<14:55,  8.37s/it, Materializing param=text_model.encoder.layers.5.mlp.fc2.bias][A
Loading weights:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 90/196 [00:25<14:47,  8.37s/it, Materializing param=text_model.encoder.layers.5.mlp.fc2.weight][A
Loading weights:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 90/196 [00:25<14:47,  8.37s/it, Materializing param=text_model.encoder.layers.5.mlp.fc2.weight][A
Loading weights:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 91/196 [00:25<14:38,  8.37s/it, Materializing param=text_model.encoder.layers.5.self_attn.k_proj.bias][A
Loading weights:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 91/196 [00:25<14:38,  8.37s/it, Materializing param=text_model.encoder.layers.5.self_attn.k_proj.bias][A
Loading weights:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 92/196 [00:25<14:30,  8.37s/it, Materializing param=text_model.encoder.layers.5.self_attn.k_proj.weight][A
Loading weights:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 92/196 [00:25<14:30,  8.37s/it, Materializing param=text_model.encoder.layers.5.self_attn.k_proj.weight][A
Loading weights:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 93/196 [00:25<14:22,  8.37s/it, Materializing param=text_model.encoder.layers.5.self_attn.out_proj.bias][A
Loading weights:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 93/196 [00:25<14:22,  8.37s/it, Materializing param=text_model.encoder.layers.5.self_attn.out_proj.bias][A
Loading weights:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 94/196 [00:25<14:13,  8.37s/it, Materializing param=text_model.encoder.layers.5.self_attn.out_proj.weight][A
Loading weights:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 94/196 [00:25<14:13,  8.37s/it, Materializing param=text_model.encoder.layers.5.self_attn.out_proj.weight][A
Loading weights:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 95/196 [00:25<14:05,  8.37s/it, Materializing param=text_model.encoder.layers.5.self_attn.q_proj.bias]    [A
Loading weights:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 95/196 [00:25<14:05,  8.37s/it, Materializing param=text_model.encoder.layers.5.self_attn.q_proj.bias][A
Loading weights:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 96/196 [00:25<13:57,  8.37s/it, Materializing param=text_model.encoder.layers.5.self_attn.q_proj.weight][A
Loading weights:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 96/196 [00:25<13:57,  8.37s/it, Materializing param=text_model.encoder.layers.5.self_attn.q_proj.weight][A
Loading weights:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 97/196 [00:25<13:48,  8.37s/it, Materializing param=text_model.encoder.layers.5.self_attn.v_proj.bias]  [A
Loading weights:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 97/196 [00:25<13:48,  8.37s/it, Materializing param=text_model.encoder.layers.5.self_attn.v_proj.bias][A
Loading weights:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 98/196 [00:25<13:40,  8.37s/it, Materializing param=text_model.encoder.layers.5.self_attn.v_proj.weight][A
Loading weights:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 98/196 [00:25<13:40,  8.37s/it, Materializing param=text_model.encoder.layers.5.self_attn.v_proj.weight][A
Loading weights:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 99/196 [00:25<13:31,  8.37s/it, Materializing param=text_model.encoder.layers.6.layer_norm1.bias]       [A
Loading weights:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 99/196 [00:25<13:31,  8.37s/it, Materializing param=text_model.encoder.layers.6.layer_norm1.bias][A
Loading weights:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 100/196 [00:25<13:23,  8.37s/it, Materializing param=text_model.encoder.layers.6.layer_norm1.weight][A
Loading weights:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 100/196 [00:25<13:23,  8.37s/it, Materializing param=text_model.encoder.layers.6.layer_norm1.weight][A
Loading weights:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 101/196 [00:25<13:15,  8.37s/it, Materializing param=text_model.encoder.layers.6.layer_norm2.bias]  [A
Loading weights:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 101/196 [00:25<13:15,  8.37s/it, Materializing param=text_model.encoder.layers.6.layer_norm2.bias][A
Loading weights:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 102/196 [00:25<13:06,  8.37s/it, Materializing param=text_model.encoder.layers.6.layer_norm2.weight][A
Loading weights:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 102/196 [00:25<13:06,  8.37s/it, Materializing param=text_model.encoder.layers.6.layer_norm2.weight][A
Loading weights:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 103/196 [00:25<12:58,  8.37s/it, Materializing param=text_model.encoder.layers.6.mlp.fc1.bias]      [A
Loading weights:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 103/196 [00:25<12:58,  8.37s/it, Materializing param=text_model.encoder.layers.6.mlp.fc1.bias][A
Loading weights:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 104/196 [00:25<12:50,  8.37s/it, Materializing param=text_model.encoder.layers.6.mlp.fc1.weight][A
Loading weights:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 104/196 [00:25<12:50,  8.37s/it, Materializing param=text_model.encoder.layers.6.mlp.fc1.weight][A
Loading weights:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 105/196 [00:25<12:41,  8.37s/it, Materializing param=text_model.encoder.layers.6.mlp.fc2.bias]  [A
Loading weights:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 105/196 [00:25<12:41,  8.37s/it, Materializing param=text_model.encoder.layers.6.mlp.fc2.bias][A
Loading weights:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 106/196 [00:25<12:33,  8.37s/it, Materializing param=text_model.encoder.layers.6.mlp.fc2.weight][A
Loading weights:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 106/196 [00:25<12:33,  8.37s/it, Materializing param=text_model.encoder.layers.6.mlp.fc2.weight][A
Loading weights:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 107/196 [00:25<12:25,  8.37s/it, Materializing param=text_model.encoder.layers.6.self_attn.k_proj.bias][A
Loading weights:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 107/196 [00:25<12:25,  8.37s/it, Materializing param=text_model.encoder.layers.6.self_attn.k_proj.bias][A
Loading weights:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 108/196 [00:25<12:16,  8.37s/it, Materializing param=text_model.encoder.layers.6.self_attn.k_proj.weight][A
Loading weights:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 108/196 [00:25<12:16,  8.37s/it, Materializing param=text_model.encoder.layers.6.self_attn.k_proj.weight][A
Loading weights:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 109/196 [00:25<12:08,  8.37s/it, Materializing param=text_model.encoder.layers.6.self_attn.out_proj.bias][A
Loading weights:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 109/196 [00:25<12:08,  8.37s/it, Materializing param=text_model.encoder.layers.6.self_attn.out_proj.bias][A
Loading weights:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 110/196 [00:25<11:59,  8.37s/it, Materializing param=text_model.encoder.layers.6.self_attn.out_proj.weight][A
Loading weights:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 110/196 [00:25<11:59,  8.37s/it, Materializing param=text_model.encoder.layers.6.self_attn.out_proj.weight][A
Loading weights:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 111/196 [00:25<11:51,  8.37s/it, Materializing param=text_model.encoder.layers.6.self_attn.q_proj.bias]    [A
Loading weights:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 111/196 [00:25<11:51,  8.37s/it, Materializing param=text_model.encoder.layers.6.self_attn.q_proj.bias][A
Loading weights:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 112/196 [00:25<11:43,  8.37s/it, Materializing param=text_model.encoder.layers.6.self_attn.q_proj.weight][A
Loading weights:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 112/196 [00:25<11:43,  8.37s/it, Materializing param=text_model.encoder.layers.6.self_attn.q_proj.weight][A
Loading weights:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 113/196 [00:25<11:34,  8.37s/it, Materializing param=text_model.encoder.layers.6.self_attn.v_proj.bias]  [A
Loading weights:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 113/196 [00:25<11:34,  8.37s/it, Materializing param=text_model.encoder.layers.6.self_attn.v_proj.bias][A
Loading weights:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 114/196 [00:25<11:26,  8.37s/it, Materializing param=text_model.encoder.layers.6.self_attn.v_proj.weight][A
Loading weights:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 114/196 [00:25<11:26,  8.37s/it, Materializing param=text_model.encoder.layers.6.self_attn.v_proj.weight][A
Loading weights:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 115/196 [00:25<11:18,  8.37s/it, Materializing param=text_model.encoder.layers.7.layer_norm1.bias]       [A
Loading weights:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 115/196 [00:25<11:18,  8.37s/it, Materializing param=text_model.encoder.layers.7.layer_norm1.bias][A
Loading weights:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 116/196 [00:25<11:09,  8.37s/it, Materializing param=text_model.encoder.layers.7.layer_norm1.weight][A
Loading weights:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 116/196 [00:25<11:09,  8.37s/it, Materializing param=text_model.encoder.layers.7.layer_norm1.weight][A
Loading weights:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 117/196 [00:25<11:01,  8.37s/it, Materializing param=text_model.encoder.layers.7.layer_norm2.bias]  [A
Loading weights:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 117/196 [00:25<11:01,  8.37s/it, Materializing param=text_model.encoder.layers.7.layer_norm2.bias][A
Loading weights:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 118/196 [00:25<10:52,  8.37s/it, Materializing param=text_model.encoder.layers.7.layer_norm2.weight][A
Loading weights:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 118/196 [00:25<10:52,  8.37s/it, Materializing param=text_model.encoder.layers.7.layer_norm2.weight][A
Loading weights:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 119/196 [00:25<10:44,  8.37s/it, Materializing param=text_model.encoder.layers.7.mlp.fc1.bias]      [A
Loading weights:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 119/196 [00:25<10:44,  8.37s/it, Materializing param=text_model.encoder.layers.7.mlp.fc1.bias][A
Loading weights:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 120/196 [00:25<10:36,  8.37s/it, Materializing param=text_model.encoder.layers.7.mlp.fc1.weight][A
Loading weights:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 120/196 [00:25<10:36,  8.37s/it, Materializing param=text_model.encoder.layers.7.mlp.fc1.weight][A
Loading weights:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 121/196 [00:25<10:27,  8.37s/it, Materializing param=text_model.encoder.layers.7.mlp.fc2.bias]  [A
Loading weights:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 121/196 [00:25<10:27,  8.37s/it, Materializing param=text_model.encoder.layers.7.mlp.fc2.bias][A
Loading weights:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 122/196 [00:25<10:19,  8.37s/it, Materializing param=text_model.encoder.layers.7.mlp.fc2.weight][A
Loading weights:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 122/196 [00:25<10:19,  8.37s/it, Materializing param=text_model.encoder.layers.7.mlp.fc2.weight][A
Loading weights:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 123/196 [00:25<10:11,  8.37s/it, Materializing param=text_model.encoder.layers.7.self_attn.k_proj.bias][A
Loading weights:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 123/196 [00:25<10:11,  8.37s/it, Materializing param=text_model.encoder.layers.7.self_attn.k_proj.bias][A
Loading weights:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 124/196 [00:25<10:02,  8.37s/it, Materializing param=text_model.encoder.layers.7.self_attn.k_proj.weight][A
Loading weights:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 124/196 [00:25<10:02,  8.37s/it, Materializing param=text_model.encoder.layers.7.self_attn.k_proj.weight][A
Loading weights:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 125/196 [00:25<09:54,  8.37s/it, Materializing param=text_model.encoder.layers.7.self_attn.out_proj.bias][A
Loading weights:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 125/196 [00:25<09:54,  8.37s/it, Materializing param=text_model.encoder.layers.7.self_attn.out_proj.bias][A
Loading weights:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 126/196 [00:25<09:45,  8.37s/it, Materializing param=text_model.encoder.layers.7.self_attn.out_proj.weight][A
Loading weights:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 126/196 [00:25<09:45,  8.37s/it, Materializing param=text_model.encoder.layers.7.self_attn.out_proj.weight][A
Loading weights:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 127/196 [00:25<09:37,  8.37s/it, Materializing param=text_model.encoder.layers.7.self_attn.q_proj.bias]    [A
Loading weights:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 127/196 [00:25<09:37,  8.37s/it, Materializing param=text_model.encoder.layers.7.self_attn.q_proj.bias][A
Loading weights:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 128/196 [00:25<09:29,  8.37s/it, Materializing param=text_model.encoder.layers.7.self_attn.q_proj.weight][A
Loading weights:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 128/196 [00:25<09:29,  8.37s/it, Materializing param=text_model.encoder.layers.7.self_attn.q_proj.weight][A
Loading weights:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 129/196 [00:25<09:20,  8.37s/it, Materializing param=text_model.encoder.layers.7.self_attn.v_proj.bias]  [A
Loading weights:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 129/196 [00:25<09:20,  8.37s/it, Materializing param=text_model.encoder.layers.7.self_attn.v_proj.bias][A
Loading weights:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 130/196 [00:25<09:12,  8.37s/it, Materializing param=text_model.encoder.layers.7.self_attn.v_proj.weight][A
Loading weights:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 130/196 [00:25<09:12,  8.37s/it, Materializing param=text_model.encoder.layers.7.self_attn.v_proj.weight][A
Loading weights:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 131/196 [00:25<09:04,  8.37s/it, Materializing param=text_model.encoder.layers.8.layer_norm1.bias]       [A
Loading weights:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 131/196 [00:25<09:04,  8.37s/it, Materializing param=text_model.encoder.layers.8.layer_norm1.bias][A
Loading weights:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 132/196 [00:25<08:55,  8.37s/it, Materializing param=text_model.encoder.layers.8.layer_norm1.weight][A
Loading weights:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 132/196 [00:25<08:55,  8.37s/it, Materializing param=text_model.encoder.layers.8.layer_norm1.weight][A
Loading weights:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 133/196 [00:25<08:47,  8.37s/it, Materializing param=text_model.encoder.layers.8.layer_norm2.bias]  [A
Loading weights:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 133/196 [00:25<08:47,  8.37s/it, Materializing param=text_model.encoder.layers.8.layer_norm2.bias][A
Loading weights:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 134/196 [00:25<08:38,  8.37s/it, Materializing param=text_model.encoder.layers.8.layer_norm2.weight][A
Loading weights:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 134/196 [00:25<08:38,  8.37s/it, Materializing param=text_model.encoder.layers.8.layer_norm2.weight][A
Loading weights:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 135/196 [00:25<08:30,  8.37s/it, Materializing param=text_model.encoder.layers.8.mlp.fc1.bias]      [A
Loading weights:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 135/196 [00:25<08:30,  8.37s/it, Materializing param=text_model.encoder.layers.8.mlp.fc1.bias][A
Loading weights:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 136/196 [00:25<08:22,  8.37s/it, Materializing param=text_model.encoder.layers.8.mlp.fc1.weight][A
Loading weights:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 136/196 [00:25<08:22,  8.37s/it, Materializing param=text_model.encoder.layers.8.mlp.fc1.weight][A
Loading weights:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 137/196 [00:25<08:13,  8.37s/it, Materializing param=text_model.encoder.layers.8.mlp.fc2.bias]  [A
Loading weights:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 137/196 [00:25<08:13,  8.37s/it, Materializing param=text_model.encoder.layers.8.mlp.fc2.bias][A
Loading weights:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 138/196 [00:25<08:05,  8.37s/it, Materializing param=text_model.encoder.layers.8.mlp.fc2.weight][A
Loading weights:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 138/196 [00:25<08:05,  8.37s/it, Materializing param=text_model.encoder.layers.8.mlp.fc2.weight][A
Loading weights:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 139/196 [00:25<07:57,  8.37s/it, Materializing param=text_model.encoder.layers.8.self_attn.k_proj.bias][A
Loading weights:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 139/196 [00:25<07:57,  8.37s/it, Materializing param=text_model.encoder.layers.8.self_attn.k_proj.bias][A
Loading weights:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 140/196 [00:25<07:48,  8.37s/it, Materializing param=text_model.encoder.layers.8.self_attn.k_proj.weight][A
Loading weights:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 140/196 [00:25<07:48,  8.37s/it, Materializing param=text_model.encoder.layers.8.self_attn.k_proj.weight][A
Loading weights:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 141/196 [00:25<07:40,  8.37s/it, Materializing param=text_model.encoder.layers.8.self_attn.out_proj.bias][A
Loading weights:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 141/196 [00:25<07:40,  8.37s/it, Materializing param=text_model.encoder.layers.8.self_attn.out_proj.bias][A
Loading weights:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 142/196 [00:25<07:32,  8.37s/it, Materializing param=text_model.encoder.layers.8.self_attn.out_proj.weight][A
Loading weights:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 142/196 [00:25<07:32,  8.37s/it, Materializing param=text_model.encoder.layers.8.self_attn.out_proj.weight][A
Loading weights:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 143/196 [00:25<07:23,  8.37s/it, Materializing param=text_model.encoder.layers.8.self_attn.q_proj.bias]    [A
Loading weights:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 143/196 [00:25<07:23,  8.37s/it, Materializing param=text_model.encoder.layers.8.self_attn.q_proj.bias][A
Loading weights:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 144/196 [00:25<07:15,  8.37s/it, Materializing param=text_model.encoder.layers.8.self_attn.q_proj.weight][A
Loading weights:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 144/196 [00:25<07:15,  8.37s/it, Materializing param=text_model.encoder.layers.8.self_attn.q_proj.weight][A
Loading weights:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 145/196 [00:25<07:06,  8.37s/it, Materializing param=text_model.encoder.layers.8.self_attn.v_proj.bias]  [A
Loading weights:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 145/196 [00:25<07:06,  8.37s/it, Materializing param=text_model.encoder.layers.8.self_attn.v_proj.bias][A
Loading weights:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 146/196 [00:25<06:58,  8.37s/it, Materializing param=text_model.encoder.layers.8.self_attn.v_proj.weight][A
Loading weights:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 146/196 [00:25<06:58,  8.37s/it, Materializing param=text_model.encoder.layers.8.self_attn.v_proj.weight][A
Loading weights:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 147/196 [00:25<06:50,  8.37s/it, Materializing param=text_model.encoder.layers.9.layer_norm1.bias]       [A
Loading weights:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 147/196 [00:25<06:50,  8.37s/it, Materializing param=text_model.encoder.layers.9.layer_norm1.bias][A
Loading weights:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 148/196 [00:25<06:41,  8.37s/it, Materializing param=text_model.encoder.layers.9.layer_norm1.weight][A
Loading weights:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 148/196 [00:25<06:41,  8.37s/it, Materializing param=text_model.encoder.layers.9.layer_norm1.weight][A
Loading weights:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 149/196 [00:25<06:33,  8.37s/it, Materializing param=text_model.encoder.layers.9.layer_norm2.bias]  [A
Loading weights:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 149/196 [00:25<06:33,  8.37s/it, Materializing param=text_model.encoder.layers.9.layer_norm2.bias][A
Loading weights:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 150/196 [00:25<06:25,  8.37s/it, Materializing param=text_model.encoder.layers.9.layer_norm2.weight][A
Loading weights:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 150/196 [00:25<06:25,  8.37s/it, Materializing param=text_model.encoder.layers.9.layer_norm2.weight][A
Loading weights:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 151/196 [00:25<06:16,  8.37s/it, Materializing param=text_model.encoder.layers.9.mlp.fc1.bias]      [A
Loading weights:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 151/196 [00:25<06:16,  8.37s/it, Materializing param=text_model.encoder.layers.9.mlp.fc1.bias][A
Loading weights:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 152/196 [00:25<06:08,  8.37s/it, Materializing param=text_model.encoder.layers.9.mlp.fc1.weight][A
Loading weights:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 152/196 [00:25<06:08,  8.37s/it, Materializing param=text_model.encoder.layers.9.mlp.fc1.weight][A
Loading weights:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 153/196 [00:25<05:59,  8.37s/it, Materializing param=text_model.encoder.layers.9.mlp.fc2.bias]  [A
Loading weights:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 153/196 [00:25<05:59,  8.37s/it, Materializing param=text_model.encoder.layers.9.mlp.fc2.bias][A
Loading weights:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 154/196 [00:25<05:51,  8.37s/it, Materializing param=text_model.encoder.layers.9.mlp.fc2.weight][A
Loading weights:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 154/196 [00:25<05:51,  8.37s/it, Materializing param=text_model.encoder.layers.9.mlp.fc2.weight][A
Loading weights:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 155/196 [00:25<05:43,  8.37s/it, Materializing param=text_model.encoder.layers.9.self_attn.k_proj.bias][A
Loading weights:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 155/196 [00:25<05:43,  8.37s/it, Materializing param=text_model.encoder.layers.9.self_attn.k_proj.bias][A
Loading weights:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 156/196 [00:25<05:34,  8.37s/it, Materializing param=text_model.encoder.layers.9.self_attn.k_proj.weight][A
Loading weights:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 156/196 [00:25<05:34,  8.37s/it, Materializing param=text_model.encoder.layers.9.self_attn.k_proj.weight][A
Loading weights:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 157/196 [00:25<05:26,  8.37s/it, Materializing param=text_model.encoder.layers.9.self_attn.out_proj.bias][A
Loading weights:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 157/196 [00:25<05:26,  8.37s/it, Materializing param=text_model.encoder.layers.9.self_attn.out_proj.bias][A
Loading weights:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 158/196 [00:25<05:18,  8.37s/it, Materializing param=text_model.encoder.layers.9.self_attn.out_proj.weight][A
Loading weights:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 158/196 [00:25<05:18,  8.37s/it, Materializing param=text_model.encoder.layers.9.self_attn.out_proj.weight][A
Loading weights:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 159/196 [00:25<05:09,  8.37s/it, Materializing param=text_model.encoder.layers.9.self_attn.q_proj.bias]    [A
Loading weights:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 159/196 [00:25<05:09,  8.37s/it, Materializing param=text_model.encoder.layers.9.self_attn.q_proj.bias][A
Loading weights:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 160/196 [00:25<05:01,  8.37s/it, Materializing param=text_model.encoder.layers.9.self_attn.q_proj.weight][A
Loading weights:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 160/196 [00:25<05:01,  8.37s/it, Materializing param=text_model.encoder.layers.9.self_attn.q_proj.weight][A
Loading weights:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 161/196 [00:25<04:52,  8.37s/it, Materializing param=text_model.encoder.layers.9.self_attn.v_proj.bias]  [A
Loading weights:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 161/196 [00:25<04:52,  8.37s/it, Materializing param=text_model.encoder.layers.9.self_attn.v_proj.bias][A
Loading weights:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 162/196 [00:25<04:44,  8.37s/it, Materializing param=text_model.encoder.layers.9.self_attn.v_proj.weight][A
Loading weights:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 162/196 [00:25<04:44,  8.37s/it, Materializing param=text_model.encoder.layers.9.self_attn.v_proj.weight][A
Loading weights:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 163/196 [00:25<04:36,  8.37s/it, Materializing param=text_model.encoder.layers.10.layer_norm1.bias]      [A
Loading weights:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 163/196 [00:25<04:36,  8.37s/it, Materializing param=text_model.encoder.layers.10.layer_norm1.bias][A
Loading weights:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 164/196 [00:25<04:27,  8.37s/it, Materializing param=text_model.encoder.layers.10.layer_norm1.weight][A
Loading weights:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 164/196 [00:25<04:27,  8.37s/it, Materializing param=text_model.encoder.layers.10.layer_norm1.weight][A
Loading weights:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 165/196 [00:25<04:19,  8.37s/it, Materializing param=text_model.encoder.layers.10.layer_norm2.bias]  [A
Loading weights:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 165/196 [00:25<04:19,  8.37s/it, Materializing param=text_model.encoder.layers.10.layer_norm2.bias][A
Loading weights:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 166/196 [00:25<04:11,  8.37s/it, Materializing param=text_model.encoder.layers.10.layer_norm2.weight][A
Loading weights:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 166/196 [00:25<04:11,  8.37s/it, Materializing param=text_model.encoder.layers.10.layer_norm2.weight][A
Loading weights:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 167/196 [00:25<04:02,  8.37s/it, Materializing param=text_model.encoder.layers.10.mlp.fc1.bias]      [A
Loading weights:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 167/196 [00:25<04:02,  8.37s/it, Materializing param=text_model.encoder.layers.10.mlp.fc1.bias][A
Loading weights:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 168/196 [00:25<03:54,  8.37s/it, Materializing param=text_model.encoder.layers.10.mlp.fc1.weight][A
Loading weights:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 168/196 [00:25<03:54,  8.37s/it, Materializing param=text_model.encoder.layers.10.mlp.fc1.weight][A
Loading weights:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 169/196 [00:25<03:46,  8.37s/it, Materializing param=text_model.encoder.layers.10.mlp.fc2.bias]  [A
Loading weights:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 169/196 [00:25<03:46,  8.37s/it, Materializing param=text_model.encoder.layers.10.mlp.fc2.bias][A
Loading weights:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 170/196 [00:25<03:37,  8.37s/it, Materializing param=text_model.encoder.layers.10.mlp.fc2.weight][A
Loading weights:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 170/196 [00:25<03:37,  8.37s/it, Materializing param=text_model.encoder.layers.10.mlp.fc2.weight][A
Loading weights:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 171/196 [00:25<03:29,  8.37s/it, Materializing param=text_model.encoder.layers.10.self_attn.k_proj.bias][A
Loading weights:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 171/196 [00:25<03:29,  8.37s/it, Materializing param=text_model.encoder.layers.10.self_attn.k_proj.bias][A
Loading weights:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 172/196 [00:25<03:20,  8.37s/it, Materializing param=text_model.encoder.layers.10.self_attn.k_proj.weight][A
Loading weights:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 172/196 [00:25<03:20,  8.37s/it, Materializing param=text_model.encoder.layers.10.self_attn.k_proj.weight][A
Loading weights:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 173/196 [00:25<03:12,  8.37s/it, Materializing param=text_model.encoder.layers.10.self_attn.out_proj.bias][A
Loading weights:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 173/196 [00:25<03:12,  8.37s/it, Materializing param=text_model.encoder.layers.10.self_attn.out_proj.bias][A
Loading weights:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 174/196 [00:25<03:04,  8.37s/it, Materializing param=text_model.encoder.layers.10.self_attn.out_proj.weight][A
Loading weights:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 174/196 [00:25<03:04,  8.37s/it, Materializing param=text_model.encoder.layers.10.self_attn.out_proj.weight][A
Loading weights:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 175/196 [00:25<02:55,  8.37s/it, Materializing param=text_model.encoder.layers.10.self_attn.q_proj.bias]    [A
Loading weights:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 175/196 [00:25<02:55,  8.37s/it, Materializing param=text_model.encoder.layers.10.self_attn.q_proj.bias][A
Loading weights:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 176/196 [00:25<02:47,  8.37s/it, Materializing param=text_model.encoder.layers.10.self_attn.q_proj.weight][A
Loading weights:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 176/196 [00:25<02:47,  8.37s/it, Materializing param=text_model.encoder.layers.10.self_attn.q_proj.weight][A
Loading weights:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 177/196 [00:25<02:39,  8.37s/it, Materializing param=text_model.encoder.layers.10.self_attn.v_proj.bias]  [A
Loading weights:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 177/196 [00:25<02:39,  8.37s/it, Materializing param=text_model.encoder.layers.10.self_attn.v_proj.bias][A
Loading weights:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 178/196 [00:25<02:30,  8.37s/it, Materializing param=text_model.encoder.layers.10.self_attn.v_proj.weight][A
Loading weights:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 178/196 [00:25<02:30,  8.37s/it, Materializing param=text_model.encoder.layers.10.self_attn.v_proj.weight][A
Loading weights:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 179/196 [00:25<02:22,  8.37s/it, Materializing param=text_model.encoder.layers.11.layer_norm1.bias]       [A
Loading weights:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 179/196 [00:25<02:22,  8.37s/it, Materializing param=text_model.encoder.layers.11.layer_norm1.bias][A
Loading weights:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 180/196 [00:25<02:13,  8.37s/it, Materializing param=text_model.encoder.layers.11.layer_norm1.weight][A
Loading weights:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 180/196 [00:25<02:13,  8.37s/it, Materializing param=text_model.encoder.layers.11.layer_norm1.weight][A
Loading weights:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 181/196 [00:25<02:05,  8.37s/it, Materializing param=text_model.encoder.layers.11.layer_norm2.bias]  [A
Loading weights:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 181/196 [00:25<02:05,  8.37s/it, Materializing param=text_model.encoder.layers.11.layer_norm2.bias][A
Loading weights:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 182/196 [00:25<01:57,  8.37s/it, Materializing param=text_model.encoder.layers.11.layer_norm2.weight][A
Loading weights:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 182/196 [00:25<01:57,  8.37s/it, Materializing param=text_model.encoder.layers.11.layer_norm2.weight][A
Loading weights:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 183/196 [00:25<01:48,  8.37s/it, Materializing param=text_model.encoder.layers.11.mlp.fc1.bias]      [A
Loading weights:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 183/196 [00:25<01:48,  8.37s/it, Materializing param=text_model.encoder.layers.11.mlp.fc1.bias][A
Loading weights:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 184/196 [00:25<01:40,  8.37s/it, Materializing param=text_model.encoder.layers.11.mlp.fc1.weight][A
Loading weights:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 184/196 [00:25<01:40,  8.37s/it, Materializing param=text_model.encoder.layers.11.mlp.fc1.weight][A
Loading weights:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 185/196 [00:25<01:32,  8.37s/it, Materializing param=text_model.encoder.layers.11.mlp.fc2.bias]  [A
Loading weights:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 185/196 [00:25<01:32,  8.37s/it, Materializing param=text_model.encoder.layers.11.mlp.fc2.bias][A
Loading weights:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 186/196 [00:25<01:23,  8.37s/it, Materializing param=text_model.encoder.layers.11.mlp.fc2.weight][A
Loading weights:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 186/196 [00:25<01:23,  8.37s/it, Materializing param=text_model.encoder.layers.11.mlp.fc2.weight][A
Loading weights:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 187/196 [00:25<01:15,  8.37s/it, Materializing param=text_model.encoder.layers.11.self_attn.k_proj.bias][A
Loading weights:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 187/196 [00:25<01:15,  8.37s/it, Materializing param=text_model.encoder.layers.11.self_attn.k_proj.bias][A
Loading weights:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 188/196 [00:25<01:06,  8.37s/it, Materializing param=text_model.encoder.layers.11.self_attn.k_proj.weight][A
Loading weights:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 188/196 [00:25<01:06,  8.37s/it, Materializing param=text_model.encoder.layers.11.self_attn.k_proj.weight][A
Loading weights:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 189/196 [00:25<00:58,  8.37s/it, Materializing param=text_model.encoder.layers.11.self_attn.out_proj.bias][A
Loading weights:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 189/196 [00:25<00:58,  8.37s/it, Materializing param=text_model.encoder.layers.11.self_attn.out_proj.bias][A
Loading weights:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 190/196 [00:25<00:50,  8.37s/it, Materializing param=text_model.encoder.layers.11.self_attn.out_proj.weight][A
Loading weights:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 190/196 [00:25<00:50,  8.37s/it, Materializing param=text_model.encoder.layers.11.self_attn.out_proj.weight][A
Loading weights:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 191/196 [00:25<00:41,  8.37s/it, Materializing param=text_model.encoder.layers.11.self_attn.q_proj.bias]    [A
Loading weights:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 191/196 [00:25<00:41,  8.37s/it, Materializing param=text_model.encoder.layers.11.self_attn.q_proj.bias][A
Loading weights:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 192/196 [00:25<00:33,  8.37s/it, Materializing param=text_model.encoder.layers.11.self_attn.q_proj.weight][A
Loading weights:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 192/196 [00:25<00:33,  8.37s/it, Materializing param=text_model.encoder.layers.11.self_attn.q_proj.weight][A
Loading weights:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 193/196 [00:25<00:25,  8.37s/it, Materializing param=text_model.encoder.layers.11.self_attn.v_proj.bias]  [A
Loading weights:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 193/196 [00:25<00:25,  8.37s/it, Materializing param=text_model.encoder.layers.11.self_attn.v_proj.bias][A
Loading weights:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 194/196 [00:25<00:16,  8.37s/it, Materializing param=text_model.encoder.layers.11.self_attn.v_proj.weight][A
Loading weights:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 194/196 [00:25<00:16,  8.37s/it, Materializing param=text_model.encoder.layers.11.self_attn.v_proj.weight][A
Loading weights:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 195/196 [00:25<00:08,  8.37s/it, Materializing param=text_model.final_layer_norm.bias]                    [A
Loading weights:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 195/196 [00:25<00:08,  8.37s/it, Materializing param=text_model.final_layer_norm.bias][A
Loading weights: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 196/196 [00:25<00:00,  8.37s/it, Materializing param=text_model.final_layer_norm.weight][A
Loading weights: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 196/196 [00:25<00:00,  8.37s/it, Materializing param=text_model.final_layer_norm.weight][ALoading weights: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 196/196 [00:25<00:00,  7.80it/s, Materializing param=text_model.final_layer_norm.weight]
CLIPTextModel LOAD REPORT from: /mnt/storage/huggingface/models--runwayml--stable-diffusion-v1-5/snapshots/451f4fe16113bff5a5d2269ed5ad43b0592e9a14/text_encoder
Key                                | Status     |  | 
-----------------------------------+------------+--+-
text_model.embeddings.position_ids | UNEXPECTED |  | 

Notes:
- UNEXPECTED	:can be ignored when loading from different task/architecture; not ok if you expect identical arch.
Loading pipeline components...:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 2/6 [03:23<05:52, 88.14s/it] Loading pipeline components...:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4/6 [03:41<01:17, 38.61s/it]Loading pipeline components...:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 5/6 [03:41<00:26, 26.71s/it]Loading pipeline components...: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [03:41<00:00, 36.94s/it]
You have disabled the safety checker for <class 'diffusers.pipelines.stable_diffusion.pipeline_stable_diffusion.StableDiffusionPipeline'> by passing `safety_checker=None`. Ensure that you abide to the conditions of the Stable Diffusion license and do not expose unfiltered results in services or applications open to the public. Both the diffusers team and Hugging Face strongly recommend to keep the safety filter enabled in all public facing circumstances, disabling it only for use-cases that involve analyzing network behavior or auditing its results. For more information, please have a look at https://github.com/huggingface/diffusers/pull/254 .
/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_validators.py:202: UserWarning: The `local_dir_use_symlinks` argument is deprecated and ignored in `hf_hub_download`. Downloading to a local directory does not use symlinks anymore.
  warnings.warn(
[Rank 1] Model loaded, syncing...
stable-diffusion-training-trainer-0-1:214:214 [0] NCCL INFO ENV/Plugin: Could not find: libnccl-env.so
stable-diffusion-training-trainer-0-1:214:214 [0] NCCL INFO cudaDriverVersion 13010
stable-diffusion-training-trainer-0-1:214:214 [0] NCCL INFO NCCL_SOCKET_IFNAME set by environment to eth0
stable-diffusion-training-trainer-0-1:214:214 [0] NCCL INFO Bootstrap: Using eth0:10.0.5.42<0>
stable-diffusion-training-trainer-0-1:214:214 [0] NCCL INFO NCCL version 2.28.9+cuda13.0
stable-diffusion-training-trainer-0-1:214:214 [0] NCCL INFO Comm config Blocking set to 1
stable-diffusion-training-trainer-0-1:214:214 [0] NCCL INFO NET/Plugin: Loaded net plugin NCCL RDMA Plugin v11 (v11)
stable-diffusion-training-trainer-0-1:214:214 [0] NCCL INFO NET/Plugin: Loaded collnet plugin SHARP (v11)
stable-diffusion-training-trainer-0-1:214:214 [0] NCCL INFO Successfully loaded external network plugin /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
stable-diffusion-training-trainer-0-1:214:214 [0] NCCL INFO NCCL_SOCKET_IFNAME set by environment to eth0
stable-diffusion-training-trainer-0-1:214:214 [0] NCCL INFO NET/Socket : Using [0]eth0:10.0.5.42<0>
stable-diffusion-training-trainer-0-1:214:214 [0] NCCL INFO Initialized NET plugin Socket
stable-diffusion-training-trainer-0-1:214:214 [0] NCCL INFO Assigned NET plugin Socket to comm
stable-diffusion-training-trainer-0-1:214:214 [0] NCCL INFO Using network Socket
stable-diffusion-training-trainer-0-1:214:214 [0] NCCL INFO ncclCommInitRankConfig comm 0x135cf750 rank 1 nranks 2 cudaDev 0 nvmlDev 0 busId f01000 commId 0x86fdd91b8fa50893 - Init START
stable-diffusion-training-trainer-0-1:214:214 [0] NCCL INFO RAS client listening socket at ::1<28028>
stable-diffusion-training-trainer-0-1:214:214 [0] NCCL INFO Bootstrap timings total 0.002775 (create 0.000027, send 0.001536, recv 0.000518, ring 0.000183, delay 0.000000)
stable-diffusion-training-trainer-0-1:214:214 [0] NCCL INFO ncclTopoGetCpuAffinity: Affinity for GPU 0 is empty, ignoring. (GPU affinity =  ; CPU affinity = 0-19).
stable-diffusion-training-trainer-0-1:214:214 [0] NCCL INFO comm 0x135cf750 rank 1 nRanks 2 nNodes 2 localRanks 1 localRank 0 MNNVL 0
stable-diffusion-training-trainer-0-1:214:214 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
stable-diffusion-training-trainer-0-1:214:214 [0] NCCL INFO P2P Chunksize set to 131072
stable-diffusion-training-trainer-0-1:214:214 [0] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so
stable-diffusion-training-trainer-0-1:214:214 [0] NCCL INFO Check P2P Type isAllDirectP2p 1 directMode 0 isAllCudaP2p 1
stable-diffusion-training-trainer-0-1:214:230 [0] NCCL INFO [Proxy Service] Device 0 CPU core 3
stable-diffusion-training-trainer-0-1:214:231 [0] NCCL INFO [Proxy Service UDS] Device 0 CPU core 10
stable-diffusion-training-trainer-0-1:214:214 [0] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so
stable-diffusion-training-trainer-0-1:214:214 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 512 | 512
stable-diffusion-training-trainer-0-1:214:214 [0] NCCL INFO 2 coll channels, 2 collnet channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
stable-diffusion-training-trainer-0-1:214:214 [0] NCCL INFO ncclCommInitRankConfig comm 0x135cf750 rank 1 nranks 2 cudaDev 0 nvmlDev 0 busId f01000 commId 0x86fdd91b8fa50893 - Init COMPLETE
stable-diffusion-training-trainer-0-1:214:214 [0] NCCL INFO Init timings - ncclCommInitRankConfig: rank 1 nranks 2 total 0.18 (kernels 0.15, alloc 0.00, bootstrap 0.00, allgathers 0.02, topo 0.00, graphs 0.00, connections 0.00, rest 0.00)
stable-diffusion-training-trainer-0-1:214:232 [0] NCCL INFO [Proxy Progress] Device 0 CPU core 2
stable-diffusion-training-trainer-0-1:214:214 [0] NCCL INFO Channel 00/0 : 0[0] -> 1[0] [receive] via NET/Socket/0
stable-diffusion-training-trainer-0-1:214:214 [0] NCCL INFO Channel 01/0 : 0[0] -> 1[0] [receive] via NET/Socket/0
stable-diffusion-training-trainer-0-1:214:214 [0] NCCL INFO Channel 00/0 : 1[0] -> 0[0] [send] via NET/Socket/0
stable-diffusion-training-trainer-0-1:214:214 [0] NCCL INFO Ch[Rank 1] Preparing dataset...
Dataset: 5 images loaded from /mnt/storage/data/train
[Rank 1] Dataset ready, syncing...
[Rank 1] Waiting for all processes...
[Rank 1] All processes ready!
annel 01/0 : 1[0] -> 0[0] [send] via NET/Socket/0
stable-diffusion-training-trainer-0-1:214:214 [0] NCCL INFO Connected all rings, use ring PXN 0 GDR 0
[rank1]:[E202 02:01:47.269337724 ProcessGroupNCCL.cpp:698] [Rank 1] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=85, OpType=BROADCAST, NumelIn=5056, NumelOut=5056, Timeout(ms)=600000) ran for 600046 milliseconds before timing out.
[rank1]:[E202 02:01:47.269448172 ProcessGroupNCCL.cpp:2288] [PG ID 0 PG GUID 0(default_pg) Rank 1]  failure detected by watchdog at work sequence id: 85 PG status: last enqueued work: 85, last completed work: 84
[rank1]:[E202 02:01:47.269456380 ProcessGroupNCCL.cpp:745] Stack trace of the failed collective not found, potentially because FlightRecorder is disabled. You can enable it by setting TORCH_NCCL_TRACE_BUFFER_SIZE to a non-zero value.
[rank1]:[E202 02:01:47.269550540 ProcessGroupNCCL.cpp:2620] [PG ID 0 PG GUID 0(default_pg) Rank 1] First PG on this rank to signal dumping.
[rank1]:[E202 02:01:48.925978481 ProcessGroupNCCL.cpp:1901] [PG ID 0 PG GUID 0(default_pg) Rank 1] Received a dump signal due to a collective timeout from this local rank and we will try our best to dump the debug info. Last enqueued NCCL work: 85, last completed NCCL work: 84.This is most likely caused by incorrect usages of collectives, e.g., wrong sizes used across ranks, the order of collectives is not same for all ranks or the scheduled collective, for some reason, didn't run. Additionally, this can be caused by GIL deadlock or other reasons such as network errors or bugs in the communications library (e.g. NCCL), etc. 
[rank1]:[E202 02:01:48.926400915 ProcessGroupNCCL.cpp:1617] [PG ID 0 PG GUID 0(default_pg) Rank 1] ProcessGroupNCCL preparing to dump debug info. Include stack trace: 1, only active collectives: 0
[rank1]:[E202 02:02:47.270271364 ProcessGroupNCCL.cpp:759] [Rank 1] Some NCCL operations have failed or timed out. Due to the asynchronous nature of CUDA kernels, subsequent GPU operations might run on corrupted/incomplete data.
[rank1]:[E202 02:02:47.270297684 ProcessGroupNCCL.cpp:773] [Rank 1] To avoid data inconsistency, we are taking the entire process down.
[rank1]:[E202 02:02:47.270914198 ProcessGroupNCCL.cpp:2104] [PG ID 0 PG GUID 0(default_pg) Rank 1] Process group watchdog thread terminated with exception: [Rank 1] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=85, OpType=BROADCAST, NumelIn=5056, NumelOut=5056, Timeout(ms)=600000) ran for 600046 milliseconds before timing out.
Exception raised from checkTimeout at /opt/pytorch/pytorch/torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:701 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0xd4 (0xfc82497412b4 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
frame #1: c10d::ProcessGroupNCCL::WorkNCCL::checkTimeout(std::optional<std::chrono::duration<long, std::ratio<1l, 1000l> > >) + 0x278 (0xfc824a73cfb8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
frame #2: c10d::ProcessGroupNCCL::Watchdog::runLoop() + 0x1154 (0xfc824a743594 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
frame #3: c10d::ProcessGroupNCCL::Watchdog::run() + 0xe0 (0xfc824a744c40 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
frame #4: <unknown function> + 0xe1ae0 (0xfc82491a1ae0 in /lib/aarch64-linux-gnu/libstdc++.so.6)
frame #5: <unknown function> + 0x8595c (0xfc82742c595c in /lib/aarch64-linux-gnu/libc.so.6)
frame #6: <unknown function> + 0xebb0c (0xfc827432bb0c in /lib/aarch64-linux-gnu/libc.so.6)

terminate called after throwing an instance of 'c10::DistBackendError'
  what():  [PG ID 0 PG GUID 0(default_pg) Rank 1] Process group watchdog thread terminated with exception: [Rank 1] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=85, OpType=BROADCAST, NumelIn=5056, NumelOut=5056, Timeout(ms)=600000) ran for 600046 milliseconds before timing out.
Exception raised from checkTimeout at /opt/pytorch/pytorch/torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:701 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0xd4 (0xfc82497412b4 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
frame #1: c10d::ProcessGroupNCCL::WorkNCCL::checkTimeout(std::optional<std::chrono::duration<long, std::ratio<1l, 1000l> > >) + 0x278 (0xfc824a73cfb8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
frame #2: c10d::ProcessGroupNCCL::Watchdog::runLoop() + 0x1154 (0xfc824a743594 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
frame #3: c10d::ProcessGroupNCCL::Watchdog::run() + 0xe0 (0xfc824a744c40 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
frame #4: <unknown function> + 0xe1ae0 (0xfc82491a1ae0 in /lib/aarch64-linux-gnu/libstdc++.so.6)
frame #5: <unknown function> + 0x8595c (0xfc82742c595c in /lib/aarch64-linux-gnu/libc.so.6)
frame #6: <unknown function> + 0xebb0c (0xfc827432bb0c in /lib/aarch64-linux-gnu/libc.so.6)

Exception raised from run at /opt/pytorch/pytorch/torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:2110 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0xd4 (0xfc82497412b4 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
frame #1: c10d::ProcessGroupNCCL::Watchdog::run() + 0x608 (0xfc824a745168 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
frame #2: <unknown function> + 0xe1ae0 (0xfc82491a1ae0 in /lib/aarch64-linux-gnu/libstdc++.so.6)
frame #3: <unknown function> + 0x8595c (0xfc82742c595c in /lib/aarch64-linux-gnu/libc.so.6)
frame #4: <unknown function> + 0xebb0c (0xfc827432bb0c in /lib/aarch64-linux-gnu/libc.so.6)

Traceback (most recent call last):
  File "/usr/local/bin/accelerate", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/accelerate/commands/accelerate_cli.py", line 50, in main
    args.func(args)
  File "/usr/local/lib/python3.12/dist-packages/accelerate/commands/launch.py", line 1281, in launch_command
    simple_launcher(args)
  File "/usr/local/lib/python3.12/dist-packages/accelerate/commands/launch.py", line 869, in simple_launcher
    raise subprocess.CalledProcessError(returncode=process.returncode, cmd=cmd)
subprocess.CalledProcessError: Command '['/usr/bin/python', '/workspace/train.py', '--model_name', 'runwayml/stable-diffusion-v1-5', '--train_data_dir', '/mnt/storage/data/train', '--output_dir', '/mnt/storage/models', '--train_method', 'lora', '--epochs', '100', '--batch_size', '1', '--learning_rate', '1e-4', '--resolution', '512']' died with <Signals.SIGABRT: 6>.
=== Training Complete ===

apiVersion: trainer.kubeflow.org/v1alpha1
kind: TrainJob
metadata:
  name: trainjob-gpu-test
  namespace: jhchoi
spec:
  managedBy: trainer.kubeflow.org/trainjob-controller
  runtimeRef:
    apiGroup: trainer.kubeflow.org
    kind: TrainingRuntime
    name: namespace-torch-distributed
  suspend: false
  trainer:
    numNodes: 1
    image: nvcr.io/nvidia/pytorch:25.01-py3
    command:
      - "bash"
      - "-c"
      - |
        # 백그라운드에서 nvidia-smi 모니터링 시작
        (
          echo "Starting nvidia-smi monitoring..."
          while true; do
            echo "======== $(date) ========"
            nvidia-smi
            sleep 5
          done
        ) &

        # 메인 Python 스크립트 실행
        python3 << 'PYTHON_SCRIPT'
        import torch
        import time

        print("="*50)
        print("PyTorch GPU Test")
        print("="*50)
        print(f"PyTorch version: {torch.__version__}")
        print(f"CUDA available: {torch.cuda.is_available()}")
        print(f"CUDA version: {torch.version.cuda}")
        print(f"GPU count: {torch.cuda.device_count()}")

        if torch.cuda.is_available():
            print(f"GPU name: {torch.cuda.get_device_name(0)}")
            print(f"GPU memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB")

            # 지속적인 GPU 부하 테스트 (3분간)
            duration_minutes = 3
            print(f"\nRunning continuous GPU stress test for {duration_minutes} minutes...")

            # 큰 행렬 생성
            x = torch.randn(10000, 10000).cuda()
            y = torch.randn(10000, 10000).cuda()

            start_time = time.time()
            iteration = 0

            while (time.time() - start_time) < (duration_minutes * 60):
                z = torch.matmul(x, y)
                torch.cuda.synchronize()
                iteration += 1

                if iteration % 100 == 0:
                    elapsed = time.time() - start_time
                    print(f"  Iteration {iteration}, Elapsed: {elapsed:.1f}s")

            total_time = time.time() - start_time
            print(f"\nCompleted {iteration} iterations in {total_time:.2f} seconds")
            print("GPU stress test successful!")
        else:
            print("WARNING: GPU not available!")

        print("="*50)
        print("Test completed.")
        PYTHON_SCRIPT
    resourcesPerNode:
      limits:
        cpu: 2
        memory: 4Gi
        nvidia.com/gpu: 1
      requests:
        cpu: 2
        memory: 4Gi
        nvidia.com/gpu: 1
  podTemplateOverrides:
    - targetJobs:
        - name: node
      spec:
        tolerations:
          - key: "nvidia.com/gpu"
            operator: "Equal"
            value: "true"
            effect: "NoSchedule"

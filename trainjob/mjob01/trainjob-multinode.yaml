apiVersion: v1
kind: Service
metadata:
  name: trainjob-multi-node-ddp
  namespace: jhchoi
spec:
  clusterIP: None  # Headless Service
  selector:
    jobset.sigs.k8s.io/jobset-name: trainjob-multi-node-ddp
  ports:
    - name: torchrun
      port: 29500
      targetPort: 29500
    # NCCL Socket 통신용 포트 범위
    - name: nccl-1
      port: 29600
      targetPort: 29600
    - name: nccl-2
      port: 29601
      targetPort: 29601
    - name: nccl-3
      port: 29602
      targetPort: 29602
    - name: nccl-4
      port: 29603
      targetPort: 29603

---

apiVersion: trainer.kubeflow.org/v1alpha1
kind: TrainJob
metadata:
  name: trainjob-multi-node-ddp
  namespace: jhchoi
spec:
  managedBy: trainer.kubeflow.org/trainjob-controller
  runtimeRef:
    apiGroup: trainer.kubeflow.org
    kind: TrainingRuntime
    name: multi-node-torch-distributed
  suspend: false
  trainer:
    numNodes: 2
    image: nvcr.io/nvidia/pytorch:25.01-py3
    command:
      - "bash"
      - "-c"
      - |
        echo "=== Environment from Training Operator ==="
        echo "PET_NNODES=$PET_NNODES"
        echo "PET_NPROC_PER_NODE=$PET_NPROC_PER_NODE"
        echo "PET_MASTER_ADDR=$PET_MASTER_ADDR"
        echo "PET_MASTER_PORT=$PET_MASTER_PORT"
        echo "PET_NODE_RANK=$PET_NODE_RANK"
        echo "HOSTNAME=$(hostname)"
        echo "POD_IP=$(hostname -i)"
        echo ""

        # Training Operator 환경변수를 표준 변수로 매핑
        export WORLD_SIZE=${PET_NNODES:-2}
        export RANK=${PET_NODE_RANK:-${JOB_COMPLETION_INDEX:-0}}
        export MASTER_ADDR=${PET_MASTER_ADDR:-$(hostname -i)}
        export MASTER_PORT=${PET_MASTER_PORT:-29500}
        export LOCAL_RANK=0

        echo "=== Mapped Environment ==="
        echo "WORLD_SIZE=$WORLD_SIZE"
        echo "RANK=$RANK"
        echo "MASTER_ADDR=$MASTER_ADDR"
        echo "MASTER_PORT=$MASTER_PORT"
        echo ""

        # Worker인 경우 Master가 준비될 때까지 대기
        if [ "$RANK" != "0" ]; then
            echo "Waiting for master to start listening on port $MASTER_PORT..."
            for i in $(seq 1 120); do
                if timeout 1 bash -c "</dev/tcp/$MASTER_ADDR/$MASTER_PORT" 2>/dev/null; then
                    echo "Master is ready!"
                    break
                fi
                echo "Waiting for master port... ($i/120)"
                sleep 1
            done
        fi

        cat > /tmp/ddp_train.py << 'EOF'
        import os
        import torch
        import torch.distributed as dist
        import torch.nn as nn
        from torch.nn.parallel import DistributedDataParallel as DDP

        def main():
            rank = int(os.environ["RANK"])
            world_size = int(os.environ["WORLD_SIZE"])
            master_addr = os.environ["MASTER_ADDR"]
            master_port = os.environ["MASTER_PORT"]
            local_rank = 0  # 노드당 1개 GPU

            print(f"[Rank {rank}] Initializing process group...", flush=True)
            print(f"[Rank {rank}] MASTER_ADDR={master_addr}, MASTER_PORT={master_port}", flush=True)
            print(f"[Rank {rank}] WORLD_SIZE={world_size}", flush=True)

            # TCP init_method 사용
            init_method = f"tcp://{master_addr}:{master_port}"
            print(f"[Rank {rank}] init_method={init_method}", flush=True)

            # GLOO backend로 테스트 (네트워크 확인용)
            dist.init_process_group(
                backend="gloo",
                init_method=init_method,
                rank=rank,
                world_size=world_size
            )

            print(f"[Rank {rank}/{world_size}] Process group initialized!", flush=True)
            print(f"[Rank {rank}/{world_size}] Running on {torch.cuda.get_device_name(local_rank)}", flush=True)

            # 모델 생성 및 DDP 래핑
            torch.cuda.set_device(local_rank)
            model = nn.Linear(1000, 1000).cuda(local_rank)
            model = DDP(model)

            # 10분간 지속적인 학습 테스트
            import time
            duration_minutes = 10

            optimizer = torch.optim.SGD(model.parameters(), lr=0.01)

            # 큰 배치로 GPU 부하 증가
            x = torch.randn(256, 1000).cuda(local_rank)

            start_time = time.time()
            iteration = 0

            if rank == 0:
                print(f"Starting {duration_minutes} minute distributed training test...", flush=True)

            while (time.time() - start_time) < (duration_minutes * 60):
                y = model(x)
                loss = y.sum()
                optimizer.zero_grad()
                loss.backward()
                optimizer.step()
                iteration += 1

                if iteration % 500 == 0 and rank == 0:
                    elapsed = time.time() - start_time
                    print(f"  Iteration {iteration}, Elapsed: {elapsed:.1f}s, Loss: {loss.item():.4f}", flush=True)

            total_time = time.time() - start_time
            if rank == 0:
                print(f"\nCompleted {iteration} iterations in {total_time:.2f} seconds", flush=True)

            dist.destroy_process_group()
            print(f"[Rank {rank}] Training completed!", flush=True)

        if __name__ == "__main__":
            main()
        EOF

        python /tmp/ddp_train.py
    env:
      - name: NCCL_DEBUG
        value: "TRACE"
      - name: NCCL_DEBUG_SUBSYS
        value: "ALL"
      - name: NCCL_SOCKET_FAMILY
        value: "AF_INET"
      - name: GLOO_SOCKET_IFNAME
        value: "eth0"
      - name: NCCL_SOCKET_IFNAME
        value: "eth0"
      # 노드 간 통신 - TCP Socket만 사용
      - name: NCCL_IB_DISABLE
        value: "1"
      - name: NCCL_P2P_DISABLE
        value: "1"
      - name: NCCL_SHM_DISABLE
        value: "1"
      - name: NCCL_NET
        value: "Socket"
      # NCCL 버퍼 및 알고리즘 설정
      - name: NCCL_BUFFSIZE
        value: "4194304"
      - name: NCCL_ALGO
        value: "Ring"
      - name: NCCL_PROTO
        value: "Simple"
      # NCCL 소켓 포트 범위 지정 (고정 포트 사용)
      - name: NCCL_SOCKET_NTHREADS
        value: "4"
      - name: NCCL_NSOCKS_PERTHREAD
        value: "1"
      # 타임아웃 증가 (기본 30분 -> 60분)
      - name: NCCL_TIMEOUT
        value: "3600"
      # 디버깅용 - 연결 재시도 횟수
      - name: NCCL_NET_GDR_LEVEL
        value: "0"
    resourcesPerNode:
      limits:
        cpu: 4
        memory: 8Gi
        nvidia.com/gpu: 1
      requests:
        cpu: 4
        memory: 8Gi
        nvidia.com/gpu: 1
  podTemplateOverrides:
    - targetJobs:
        - name: node
      spec:
        tolerations:
          - key: "nvidia.com/gpu"
            operator: "Equal"
            value: "true"
            effect: "NoSchedule"

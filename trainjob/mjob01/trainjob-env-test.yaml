apiVersion: trainer.kubeflow.org/v1alpha1
kind: TrainJob
metadata:
  name: trainjob-env-test
  namespace: jhchoi
spec:
  managedBy: trainer.kubeflow.org/trainjob-controller
  runtimeRef:
    apiGroup: trainer.kubeflow.org
    kind: TrainingRuntime
    name: multi-node-torch-distributed
  suspend: false
  trainer:
    numNodes: 2
    image: nvcr.io/nvidia/pytorch:25.01-py3
    command:
      - "bash"
      - "-c"
      - |
        echo "=== Environment Variables ==="
        echo "MASTER_ADDR=$MASTER_ADDR"
        echo "MASTER_PORT=$MASTER_PORT"
        echo "RANK=$RANK"
        echo "WORLD_SIZE=$WORLD_SIZE"
        echo "LOCAL_RANK=$LOCAL_RANK"
        echo ""
        echo "=== GPU Info ==="
        python3 -c "import torch; print(f'CUDA available: {torch.cuda.is_available()}'); print(f'GPU count: {torch.cuda.device_count()}')"
        echo ""
        echo "=== Waiting 60s for log inspection ==="
        sleep 60
    resourcesPerNode:
      limits:
        cpu: 4
        memory: 8Gi
        nvidia.com/gpu: 1
      requests:
        cpu: 4
        memory: 8Gi
        nvidia.com/gpu: 1
  podTemplateOverrides:
    - targetJobs:
        - name: node
      spec:
        tolerations:
          - key: "nvidia.com/gpu"
            operator: "Equal"
            value: "true"
            effect: "NoSchedule"
